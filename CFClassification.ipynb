{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "careful-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from parse import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "caring-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show classification report for Cross Validation\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "parallel-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robust          368\n",
      "prefrail_mci    268\n",
      "prefrail        250\n",
      "mci             142\n",
      "frail_mci        86\n",
      "frail             9\n",
      "Name: condition, dtype: int64\n",
      "\n",
      "####################################################################\n",
      "Number of Rows of Dataframe:\n",
      "1123\n",
      "Number of Columns of Dataframe:\n",
      "59\n",
      "\n",
      "####################################################################\n",
      "Threshold for number of NULLs in a column: 0.1095\n",
      "Number of Columns before Parsing for Too Many NULLs in a column:\n",
      "59\n",
      "Number of Columns after Parsing for Too Many NULLs in a column:\n",
      "51\n",
      "\n",
      "Columns Removed:\n",
      "B1_b5\n",
      "B4_a1\n",
      "B4_a3\n",
      "B4_a4\n",
      "B4_a6\n",
      "B4_b1\n",
      "B4_b3\n",
      "B5_a1\n",
      "\n",
      "####################################################################\n",
      "Number of Columns after dropping A1_2, B1_b4, B2_c3, B4_b2 for inconsistent data types:\n",
      "47\n",
      "\n",
      "####################################################################\n",
      "Number of Rows before Parsing NULLs in data:\n",
      "1123\n",
      "Number of Rows after Parsing NULLs in data:\n",
      "1015\n"
     ]
    }
   ],
   "source": [
    "# Pre-parse the dataset\n",
    "data = preprocess(\"rawfile_blood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "chubby-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################################\n",
      "Labels with frequencies:\n",
      "Frail: 7\n",
      "Frail + MCI: 76\n",
      "MCI: 133\n",
      "Prefrail + MCI: 233\n",
      "Prefrail: 223\n",
      "Robust: 343\n"
     ]
    }
   ],
   "source": [
    "# Initialise counters for each condition\n",
    "frail = 0\n",
    "frail_mci = 0\n",
    "mci = 0\n",
    "prefrail_mci = 0\n",
    "prefrail = 0\n",
    "robust = 0\n",
    "\n",
    "# Count rows of data for each condition\n",
    "for i in range(0, len(data)):\n",
    "\tif data.at[i, 'condition'] == 'frail':\n",
    "\t\tfrail += 1\n",
    "\telif data.at[i, 'condition'] == 'frail_mci':\n",
    "\t\tfrail_mci += 1\n",
    "\telif data.at[i, 'condition'] == 'mci':\n",
    "\t\tmci += 1\n",
    "\telif data.at[i, 'condition'] == 'prefrail_mci':\n",
    "\t\tprefrail_mci += 1\n",
    "\telif data.at[i, 'condition'] == 'prefrail':\n",
    "\t\tprefrail += 1\n",
    "\telif data.at[i, 'condition'] == 'robust':\n",
    "\t\trobust += 1\n",
    "        \n",
    "# Display number of rows (frequency) for each condition (label)\n",
    "print(\"\\n####################################################################\")\n",
    "print(\"Labels with frequencies:\")\n",
    "print(\"Frail:\", frail)\n",
    "print(\"Frail + MCI:\", frail_mci)\n",
    "print(\"MCI:\", mci)\n",
    "print(\"Prefrail + MCI:\", prefrail_mci)\n",
    "print(\"Prefrail:\", prefrail)\n",
    "print(\"Robust:\", robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "british-rolling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME02646</td>\n",
       "      <td>frail</td>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "      <td>46.5</td>\n",
       "      <td>121</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ME03109</td>\n",
       "      <td>frail</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>55.6</td>\n",
       "      <td>142</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>87</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ME06997</td>\n",
       "      <td>frail</td>\n",
       "      <td>441</td>\n",
       "      <td>20</td>\n",
       "      <td>76.8</td>\n",
       "      <td>105</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.023</td>\n",
       "      <td>2.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ME07149</td>\n",
       "      <td>frail</td>\n",
       "      <td>265</td>\n",
       "      <td>16</td>\n",
       "      <td>47.2</td>\n",
       "      <td>122</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.06</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME07700</td>\n",
       "      <td>frail</td>\n",
       "      <td>425</td>\n",
       "      <td>14</td>\n",
       "      <td>31.3</td>\n",
       "      <td>124</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mtag condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  ...  \\\n",
       "0  ME02646     frail   196    24  46.5   121   3.93   0.37     95     31  ...   \n",
       "1  ME03109     frail   200    23  55.6   142   4.82   0.42     87     30  ...   \n",
       "2  ME06997     frail   441    20  76.8   105   4.54   0.41     90     30  ...   \n",
       "3  ME07149     frail   265    16  47.2   122   4.53   0.39     86     27  ...   \n",
       "4  ME07700     frail   425    14  31.3   124   4.44   0.38     85     28  ...   \n",
       "\n",
       "   B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "0      7     12     13      6  0.2    6.0  1.011   1.14    4.1  5.9  \n",
       "1      7     20     17     26  3.1    5.0  1.011   3.25    4.6  8.5  \n",
       "2      5     16     19     15  1.4    7.0  1.023   2.14    4.0  6.4  \n",
       "3      8     24     19     21  2.1    5.5  1.012   1.06    4.7  6.1  \n",
       "4      6     20     23     23  6.0    5.5  1.013   1.95    3.8  5.8  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "regulation-dominican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mtag', 'condition', 'A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
       "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
       "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
       "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
       "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
       "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "expressed-allergy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "robust          343\n",
       "prefrail_mci    233\n",
       "prefrail        223\n",
       "mci             133\n",
       "frail_mci        76\n",
       "frail             7\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = data['condition'].value_counts()\n",
    "condition = c.index\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "fossil-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(data)):\n",
    "# \tif data.at[i, 'condition'] == 'frail':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'frail_mci':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'mci':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'prefrail_mci':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'prefrail':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'robust':\n",
    "# \t\tdata.at[i, 'condition'] = 'robust'\n",
    "\n",
    "# df1 = data[data.condition == 'frail_mci']\n",
    "# df1 = df1.reset_index(drop=True)\n",
    "\n",
    "# df2 = data[data.condition == 'robust']\n",
    "# df2 = df2.reset_index(drop=True)\n",
    "\n",
    "# data = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "noticed-surprise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME02646</td>\n",
       "      <td>frail</td>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "      <td>46.5</td>\n",
       "      <td>121</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ME03109</td>\n",
       "      <td>frail</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>55.6</td>\n",
       "      <td>142</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>87</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ME06997</td>\n",
       "      <td>frail</td>\n",
       "      <td>441</td>\n",
       "      <td>20</td>\n",
       "      <td>76.8</td>\n",
       "      <td>105</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.023</td>\n",
       "      <td>2.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ME07149</td>\n",
       "      <td>frail</td>\n",
       "      <td>265</td>\n",
       "      <td>16</td>\n",
       "      <td>47.2</td>\n",
       "      <td>122</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.06</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME07700</td>\n",
       "      <td>frail</td>\n",
       "      <td>425</td>\n",
       "      <td>14</td>\n",
       "      <td>31.3</td>\n",
       "      <td>124</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mtag condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  ...  \\\n",
       "0  ME02646     frail   196    24  46.5   121   3.93   0.37     95     31  ...   \n",
       "1  ME03109     frail   200    23  55.6   142   4.82   0.42     87     30  ...   \n",
       "2  ME06997     frail   441    20  76.8   105   4.54   0.41     90     30  ...   \n",
       "3  ME07149     frail   265    16  47.2   122   4.53   0.39     86     27  ...   \n",
       "4  ME07700     frail   425    14  31.3   124   4.44   0.38     85     28  ...   \n",
       "\n",
       "   B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "0      7     12     13      6  0.2    6.0  1.011   1.14    4.1  5.9  \n",
       "1      7     20     17     26  3.1    5.0  1.011   3.25    4.6  8.5  \n",
       "2      5     16     19     15  1.4    7.0  1.023   2.14    4.0  6.4  \n",
       "3      8     24     19     21  2.1    5.5  1.012   1.06    4.7  6.1  \n",
       "4      6     20     23     23  6.0    5.5  1.013   1.95    3.8  5.8  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "colonial-animation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>MV00454</td>\n",
       "      <td>robust</td>\n",
       "      <td>220</td>\n",
       "      <td>19</td>\n",
       "      <td>67.5</td>\n",
       "      <td>138</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>MV00456</td>\n",
       "      <td>robust</td>\n",
       "      <td>334</td>\n",
       "      <td>18</td>\n",
       "      <td>51.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>MV00460</td>\n",
       "      <td>robust</td>\n",
       "      <td>418</td>\n",
       "      <td>17</td>\n",
       "      <td>61.0</td>\n",
       "      <td>122</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.005</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>MV00502</td>\n",
       "      <td>robust</td>\n",
       "      <td>393</td>\n",
       "      <td>18</td>\n",
       "      <td>43.1</td>\n",
       "      <td>136</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>MV00510</td>\n",
       "      <td>robust</td>\n",
       "      <td>371</td>\n",
       "      <td>24</td>\n",
       "      <td>55.9</td>\n",
       "      <td>127</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.017</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mtag condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "1010  MV00454    robust   220    19  67.5   138   4.66   0.42     91     30   \n",
       "1011  MV00456    robust   334    18  51.0   139   4.63   0.42     91     30   \n",
       "1012  MV00460    robust   418    17  61.0   122   4.18   0.38     90     29   \n",
       "1013  MV00502    robust   393    18  43.1   136   4.57   0.43     94     30   \n",
       "1014  MV00510    robust   371    24  55.9   127   4.41   0.40     90     29   \n",
       "\n",
       "      ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "1010  ...     20     10     17      8  6.6    7.0  1.015   1.29    4.5  6.2  \n",
       "1011  ...     16     22     35     40  1.0    6.0  1.015   1.88    3.9  5.6  \n",
       "1012  ...     19     20     23     15  0.4    6.5  1.005   3.58    4.0  5.6  \n",
       "1013  ...     13     11     22     23  0.7    7.0  1.009   0.92    4.1  6.0  \n",
       "1014  ...     13     14     16     12  7.5    8.0  1.017   2.45    4.5  6.2  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "interested-blowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "robust          343\n",
       "prefrail_mci    233\n",
       "prefrail        223\n",
       "mci             133\n",
       "frail_mci        76\n",
       "frail             7\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = data['condition'].value_counts()\n",
    "condition = c.index\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "sixth-familiar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME02646</td>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "      <td>46.5</td>\n",
       "      <td>121</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ME03109</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>55.6</td>\n",
       "      <td>142</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>87</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ME06997</td>\n",
       "      <td>5</td>\n",
       "      <td>441</td>\n",
       "      <td>20</td>\n",
       "      <td>76.8</td>\n",
       "      <td>105</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.023</td>\n",
       "      <td>2.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "0  ME02646          5   196    24  46.5   121   3.93   0.37     95     31   \n",
       "1  ME03109          5   200    23  55.6   142   4.82   0.42     87     30   \n",
       "2  ME06997          5   441    20  76.8   105   4.54   0.41     90     30   \n",
       "\n",
       "   ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "0  ...      7     12     13      6  0.2    6.0  1.011   1.14    4.1  5.9  \n",
       "1  ...      7     20     17     26  3.1    5.0  1.011   3.25    4.6  8.5  \n",
       "2  ...      5     16     19     15  1.4    7.0  1.023   2.14    4.0  6.4  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(condition)):\n",
    "    data['condition'].replace(condition[i], i, inplace = True)\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "prescription-disabled",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>MV00454</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>19</td>\n",
       "      <td>67.5</td>\n",
       "      <td>138</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>MV00456</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>18</td>\n",
       "      <td>51.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>MV00460</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>17</td>\n",
       "      <td>61.0</td>\n",
       "      <td>122</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.005</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>MV00502</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>18</td>\n",
       "      <td>43.1</td>\n",
       "      <td>136</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>MV00510</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>24</td>\n",
       "      <td>55.9</td>\n",
       "      <td>127</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.017</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "1010  MV00454          0   220    19  67.5   138   4.66   0.42     91     30   \n",
       "1011  MV00456          0   334    18  51.0   139   4.63   0.42     91     30   \n",
       "1012  MV00460          0   418    17  61.0   122   4.18   0.38     90     29   \n",
       "1013  MV00502          0   393    18  43.1   136   4.57   0.43     94     30   \n",
       "1014  MV00510          0   371    24  55.9   127   4.41   0.40     90     29   \n",
       "\n",
       "      ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "1010  ...     20     10     17      8  6.6    7.0  1.015   1.29    4.5  6.2  \n",
       "1011  ...     16     22     35     40  1.0    6.0  1.015   1.88    3.9  5.6  \n",
       "1012  ...     19     20     23     15  0.4    6.5  1.005   3.58    4.0  5.6  \n",
       "1013  ...     13     11     22     23  0.7    7.0  1.009   0.92    4.1  6.0  \n",
       "1014  ...     13     14     16     12  7.5    8.0  1.017   2.45    4.5  6.2  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "behavioral-champagne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mtag', 'condition', 'A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
       "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
       "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
       "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
       "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
       "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "sexual-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['condition']\n",
    "\n",
    "features = ['A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
    "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
    "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
    "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
    "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
    "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6']\n",
    "X_old = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "documentary-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_old\n",
    "X = StandardScaler().fit_transform(X_old)\n",
    "X = MinMaxScaler().fit_transform(X_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "modern-steal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 343, 1: 233, 2: 223, 3: 133, 4: 76, 5: 7})\n"
     ]
    }
   ],
   "source": [
    "# Summarise the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "satellite-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the majority class\n",
    "# Define undersample strategy\n",
    "\n",
    "# 75% of majority class\n",
    "# sampling_strategy = {0: 254, 1: 231, 2: 221, 3: 133, 4: 76, 5: 7}\n",
    "\n",
    "# 50% of majority class\n",
    "# sampling_strategy = {0: 170, 1: 170, 2: 170, 3: 133, 4: 76, 5: 7}\n",
    "\n",
    "# 25% of majority class\n",
    "# sampling_strategy = {0: 85, 1: 85, 2: 85, 3: 85, 4: 76, 5: 7}\n",
    "\n",
    "# sampling_strategy = {0: 76, 1: 76}\n",
    "# undersample = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "\n",
    "# 50% of majority class\n",
    "# undersample = RandomUnderSampler(sampling_strategy=0.0413)\n",
    "\n",
    "# 25% of majority class\n",
    "# undersample = RandomUnderSampler(sampling_strategy=0.0826)\n",
    "\n",
    "# X, y = undersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "chief-trouble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 343, 1: 233, 2: 223, 3: 133, 4: 76, 5: 7})\n"
     ]
    }
   ],
   "source": [
    "# Summarise the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "controlling-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015,)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "through-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 45)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "major-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset using SMOTE\n",
    "# oversample = SMOTE()\n",
    "# X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "advance-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 343, 1: 233, 2: 223, 3: 133, 4: 76, 5: 7})\n"
     ]
    }
   ],
   "source": [
    "# Summarise the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "practical-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015,)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "stable-treasurer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 45)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "cathedral-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Using the entire dataset as both the train and test sets without splitting into separate train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "shared-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.427\n",
      "Linear Discriminant Analysis: 0.448\n",
      "K-Nearest Neigbors: 0.511\n",
      "Classification and Regression Trees: 1.0\n",
      "Gaussian Naive Bayes: 0.391\n",
      "Support Vector Machines: 0.41\n",
      "Random Forest Classifier: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X, y)\n",
    "print(\"Logistic Regression:\", log_model.score(X, y).round(3))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X, y)\n",
    "print(\"Linear Discriminant Analysis:\", lda_model.score(X, y).round(3))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "print(\"K-Nearest Neigbors:\", knn_model.score(X, y).round(3))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "print(\"Classification and Regression Trees:\", cart_model.score(X, y).round(3))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "print(\"Gaussian Naive Bayes:\", gnb_model.score(X, y).round(3))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "print(\"Support Vector Machines:\", svm_model.score(X, y).round(3))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "print(\"Random Forest Classifier:\", rfc_model.score(X, y).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "rotary-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Splitting the dataset into separate train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "hispanic-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.382\n",
      "Linear Discriminant Analysis: 0.357\n",
      "K-Nearest Neigbors: 0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification and Regression Trees: 0.241\n",
      "Gaussian Naive Bayes: 0.369\n",
      "Support Vector Machines: 0.382\n",
      "Random Forest Classifier: 0.387\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1)\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression:\", log_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train)\n",
    "print(\"Linear Discriminant Analysis:\", lda_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"K-Nearest Neigbors:\", knn_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X_train, y_train)\n",
    "print(\"Classification and Regression Trees:\", cart_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)\n",
    "print(\"Gaussian Naive Bayes:\", gnb_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(\"Support Vector Machines:\", svm_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train)\n",
    "print(\"Random Forest Classifier:\", rfc_model.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "modular-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "necessary-casting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.37 accuracy with a standard deviation of 0.04\n",
      "Linear Discriminant Analysis: 0.36 accuracy with a standard deviation of 0.03\n",
      "K-Nearest Neighbors: 0.31 accuracy with a standard deviation of 0.02\n",
      "Classification and Regression Trees: 0.27 accuracy with a standard deviation of 0.03\n",
      "Gaussian Naive Bayes: 0.33 accuracy with a standard deviation of 0.03\n",
      "Support Vector Machines: 0.37 accuracy with a standard deviation of 0.03\n",
      "Random Forest Classifier: 0.35 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X, y)\n",
    "scores = cross_val_score(log_model, X, y, cv=5)\n",
    "print(\"Logistic Regression: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X, y)\n",
    "scores = cross_val_score(lda_model, X, y, cv=5)\n",
    "print(\"Linear Discriminant Analysis: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5)\n",
    "print(\"K-Nearest Neighbors: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5)\n",
    "print(\"Classification and Regression Trees: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5)\n",
    "print(\"Gaussian Naive Bayes: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5)\n",
    "print(\"Support Vector Machines: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5)\n",
    "print(\"Random Forest Classifier: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ultimate-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.90      0.57        68\n",
      "           1       0.41      0.37      0.39        46\n",
      "           2       0.44      0.16      0.23        45\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.42       203\n",
      "   macro avg       0.21      0.24      0.20       203\n",
      "weighted avg       0.33      0.42      0.33       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.69      0.51        68\n",
      "           1       0.34      0.43      0.38        47\n",
      "           2       0.17      0.09      0.12        45\n",
      "           3       0.50      0.04      0.07        26\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.35       203\n",
      "   macro avg       0.23      0.21      0.18       203\n",
      "weighted avg       0.31      0.35      0.29       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.77      0.55        69\n",
      "           1       0.37      0.40      0.39        47\n",
      "           2       0.21      0.11      0.15        44\n",
      "           3       0.17      0.04      0.06        26\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38       203\n",
      "   macro avg       0.20      0.22      0.19       203\n",
      "weighted avg       0.30      0.38      0.32       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.86      0.56        69\n",
      "           1       0.33      0.32      0.32        47\n",
      "           2       0.20      0.07      0.10        44\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38       203\n",
      "   macro avg       0.16      0.21      0.16       203\n",
      "weighted avg       0.26      0.38      0.29       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.72      0.49        69\n",
      "           1       0.20      0.22      0.21        46\n",
      "           2       0.15      0.04      0.07        45\n",
      "           3       0.33      0.04      0.07        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31       203\n",
      "   macro avg       0.18      0.17      0.14       203\n",
      "weighted avg       0.25      0.31      0.24       203\n",
      "\n",
      "[0.41871921 0.3546798  0.38423645 0.37931034 0.31034483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "scores = cross_val_score(log_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "amended-quick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.79      0.56        68\n",
      "           1       0.46      0.46      0.46        46\n",
      "           2       0.32      0.16      0.21        45\n",
      "           3       0.20      0.04      0.06        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.41       203\n",
      "   macro avg       0.23      0.24      0.21       203\n",
      "weighted avg       0.35      0.41      0.35       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.60      0.49        68\n",
      "           1       0.42      0.45      0.43        47\n",
      "           2       0.12      0.09      0.10        45\n",
      "           3       0.11      0.04      0.06        26\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33       203\n",
      "   macro avg       0.18      0.20      0.18       203\n",
      "weighted avg       0.28      0.33      0.30       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.67      0.53        69\n",
      "           1       0.29      0.34      0.31        47\n",
      "           2       0.36      0.20      0.26        44\n",
      "           3       0.27      0.12      0.16        26\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36       203\n",
      "   macro avg       0.23      0.22      0.21       203\n",
      "weighted avg       0.33      0.36      0.33       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.70      0.52        69\n",
      "           1       0.36      0.40      0.38        47\n",
      "           2       0.24      0.11      0.15        44\n",
      "           3       0.14      0.04      0.06        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36       203\n",
      "   macro avg       0.19      0.21      0.19       203\n",
      "weighted avg       0.30      0.36      0.31       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.62      0.46        69\n",
      "           1       0.28      0.28      0.28        46\n",
      "           2       0.30      0.13      0.18        45\n",
      "           3       0.30      0.11      0.16        27\n",
      "           4       0.14      0.07      0.09        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33       203\n",
      "   macro avg       0.23      0.20      0.20       203\n",
      "weighted avg       0.30      0.33      0.29       203\n",
      "\n",
      "[0.408867   0.33004926 0.36453202 0.35960591 0.32512315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "scores = cross_val_score(lda_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "noted-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.71      0.48        68\n",
      "           1       0.39      0.30      0.34        46\n",
      "           2       0.20      0.09      0.12        45\n",
      "           3       0.07      0.04      0.05        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33       203\n",
      "   macro avg       0.17      0.19      0.17       203\n",
      "weighted avg       0.26      0.33      0.27       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.59      0.44        68\n",
      "           1       0.18      0.17      0.18        47\n",
      "           2       0.21      0.16      0.18        45\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.27       203\n",
      "   macro avg       0.13      0.15      0.13       203\n",
      "weighted avg       0.21      0.27      0.23       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.59      0.45        69\n",
      "           1       0.24      0.21      0.23        47\n",
      "           2       0.18      0.14      0.16        44\n",
      "           3       0.09      0.04      0.05        26\n",
      "           4       0.67      0.12      0.21        16\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.30       203\n",
      "   macro avg       0.26      0.18      0.18       203\n",
      "weighted avg       0.28      0.30      0.26       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.68      0.47        69\n",
      "           1       0.31      0.26      0.28        47\n",
      "           2       0.16      0.09      0.12        44\n",
      "           3       0.12      0.04      0.06        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32       203\n",
      "   macro avg       0.16      0.18      0.15       203\n",
      "weighted avg       0.25      0.32      0.26       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.64      0.47        69\n",
      "           1       0.30      0.28      0.29        46\n",
      "           2       0.30      0.13      0.18        45\n",
      "           3       0.17      0.11      0.13        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33       203\n",
      "   macro avg       0.19      0.19      0.18       203\n",
      "weighted avg       0.28      0.33      0.28       203\n",
      "\n",
      "[0.33004926 0.27093596 0.2955665  0.31527094 0.32512315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neigbors\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "foreign-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45        68\n",
      "           1       0.34      0.35      0.34        46\n",
      "           2       0.24      0.18      0.20        45\n",
      "           3       0.10      0.11      0.11        27\n",
      "           4       0.33      0.20      0.25        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.32       203\n",
      "   macro avg       0.24      0.22      0.23       203\n",
      "weighted avg       0.31      0.32      0.31       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.29      0.34        68\n",
      "           1       0.26      0.28      0.27        47\n",
      "           2       0.21      0.22      0.22        45\n",
      "           3       0.07      0.08      0.07        26\n",
      "           4       0.12      0.20      0.15        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.24       203\n",
      "   macro avg       0.18      0.18      0.17       203\n",
      "weighted avg       0.26      0.24      0.24       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.25      0.26        69\n",
      "           1       0.17      0.19      0.18        47\n",
      "           2       0.14      0.16      0.15        44\n",
      "           3       0.07      0.08      0.07        26\n",
      "           4       0.12      0.06      0.08        16\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.18       203\n",
      "   macro avg       0.13      0.12      0.12       203\n",
      "weighted avg       0.18      0.18      0.18       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.45      0.44        69\n",
      "           1       0.25      0.23      0.24        47\n",
      "           2       0.24      0.20      0.22        44\n",
      "           3       0.13      0.15      0.14        27\n",
      "           4       0.13      0.13      0.13        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.28       203\n",
      "   macro avg       0.20      0.19      0.19       203\n",
      "weighted avg       0.28      0.28      0.28       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.41      0.39        69\n",
      "           1       0.25      0.13      0.17        46\n",
      "           2       0.23      0.27      0.24        45\n",
      "           3       0.18      0.19      0.18        27\n",
      "           4       0.05      0.07      0.06        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26       203\n",
      "   macro avg       0.18      0.18      0.17       203\n",
      "weighted avg       0.26      0.26      0.25       203\n",
      "\n",
      "[0.31527094 0.2364532  0.1773399  0.28078818 0.25615764]\n"
     ]
    }
   ],
   "source": [
    "# Classification and Regression Trees\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "documentary-command",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.66      0.51        68\n",
      "           1       0.41      0.24      0.30        46\n",
      "           2       0.33      0.16      0.21        45\n",
      "           3       0.24      0.30      0.26        27\n",
      "           4       0.20      0.13      0.16        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.36       203\n",
      "   macro avg       0.26      0.25      0.24       203\n",
      "weighted avg       0.35      0.36      0.33       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.50      0.42        68\n",
      "           1       0.32      0.21      0.26        47\n",
      "           2       0.11      0.04      0.06        45\n",
      "           3       0.18      0.27      0.22        26\n",
      "           4       0.19      0.27      0.22        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.28       203\n",
      "   macro avg       0.20      0.22      0.20       203\n",
      "weighted avg       0.26      0.28      0.26       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.64      0.51        69\n",
      "           1       0.16      0.15      0.16        47\n",
      "           2       0.12      0.02      0.04        44\n",
      "           3       0.20      0.27      0.23        26\n",
      "           4       0.08      0.06      0.07        16\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.30       203\n",
      "   macro avg       0.17      0.19      0.17       203\n",
      "weighted avg       0.24      0.30      0.25       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.71      0.54        69\n",
      "           1       0.33      0.28      0.30        47\n",
      "           2       0.43      0.14      0.21        44\n",
      "           3       0.16      0.15      0.15        27\n",
      "           4       0.20      0.13      0.16        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36       203\n",
      "   macro avg       0.26      0.23      0.23       203\n",
      "weighted avg       0.35      0.36      0.33       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.75      0.54        69\n",
      "           1       0.19      0.09      0.12        46\n",
      "           2       0.38      0.11      0.17        45\n",
      "           3       0.12      0.11      0.12        27\n",
      "           4       0.21      0.20      0.21        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33       203\n",
      "   macro avg       0.22      0.21      0.19       203\n",
      "weighted avg       0.30      0.33      0.28       203\n",
      "\n",
      "[0.35960591 0.28078818 0.2955665  0.36453202 0.33004926]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "balanced-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.94      0.55        68\n",
      "           1       0.46      0.35      0.40        46\n",
      "           2       0.00      0.00      0.00        45\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.39       203\n",
      "   macro avg       0.14      0.21      0.16       203\n",
      "weighted avg       0.23      0.39      0.27       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.79      0.54        68\n",
      "           1       0.34      0.43      0.38        47\n",
      "           2       0.08      0.02      0.04        45\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.37       203\n",
      "   macro avg       0.14      0.21      0.16       203\n",
      "weighted avg       0.23      0.37      0.28       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.86      0.54        69\n",
      "           1       0.39      0.36      0.37        47\n",
      "           2       0.18      0.05      0.07        44\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38       203\n",
      "   macro avg       0.16      0.21      0.17       203\n",
      "weighted avg       0.26      0.38      0.29       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.96      0.57        69\n",
      "           1       0.38      0.30      0.33        47\n",
      "           2       0.33      0.02      0.04        44\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40       203\n",
      "   macro avg       0.19      0.21      0.16       203\n",
      "weighted avg       0.30      0.40      0.28       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.77      0.48        69\n",
      "           1       0.21      0.22      0.21        46\n",
      "           2       0.00      0.00      0.00        45\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31       203\n",
      "   macro avg       0.09      0.16      0.12       203\n",
      "weighted avg       0.17      0.31      0.21       203\n",
      "\n",
      "[0.39408867 0.36945813 0.38423645 0.39901478 0.31034483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "tutorial-liabilities",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.82      0.54        68\n",
      "           1       0.33      0.28      0.31        46\n",
      "           2       0.25      0.13      0.17        45\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.37       203\n",
      "   macro avg       0.16      0.21      0.17       203\n",
      "weighted avg       0.26      0.37      0.29       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.66      0.50        68\n",
      "           1       0.27      0.38      0.32        47\n",
      "           2       0.18      0.09      0.12        45\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33       203\n",
      "   macro avg       0.14      0.19      0.16       203\n",
      "weighted avg       0.24      0.33      0.27       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50        69\n",
      "           1       0.31      0.40      0.35        47\n",
      "           2       0.20      0.11      0.14        44\n",
      "           3       0.00      0.00      0.00        26\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.34       203\n",
      "   macro avg       0.15      0.20      0.17       203\n",
      "weighted avg       0.25      0.34      0.28       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.86      0.58        69\n",
      "           1       0.32      0.28      0.30        47\n",
      "           2       0.25      0.14      0.18        44\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.38       203\n",
      "   macro avg       0.17      0.21      0.18       203\n",
      "weighted avg       0.28      0.38      0.30       203\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.67      0.46        69\n",
      "           1       0.34      0.37      0.35        46\n",
      "           2       0.00      0.00      0.00        45\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.67      0.13      0.22        15\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32       203\n",
      "   macro avg       0.23      0.19      0.17       203\n",
      "weighted avg       0.24      0.32      0.25       203\n",
      "\n",
      "[0.36945813 0.33004926 0.34482759 0.38423645 0.32019704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "persistent-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Performance Metrics for Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "wrong-struggle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for Logistic Regression:\n",
      "\n",
      "0.38177 \n",
      "\n",
      "[[108  19  20   0   0   0]\n",
      " [ 45  32  12   0   0   0]\n",
      " [ 47  18  15   0   0   0]\n",
      " [ 26  14  11   0   0   0]\n",
      " [ 12  19   3   0   0   0]\n",
      " [  3   2   0   0   0   0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.73      0.56       147\n",
      "           1       0.31      0.36      0.33        89\n",
      "           2       0.25      0.19      0.21        80\n",
      "           3       0.00      0.00      0.00        51\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.38       406\n",
      "   macro avg       0.17      0.21      0.18       406\n",
      "weighted avg       0.28      0.38      0.32       406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Logistic Regression\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for Logistic Regression:\\n')\n",
    "print(accuracy_score(y_test, log_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, log_pred), '\\n')\n",
    "print(classification_report(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "familiar-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for LDA:\n",
      "\n",
      "0.35714 \n",
      "\n",
      "[[92 25 26  3  1  0]\n",
      " [32 32 17  5  2  1]\n",
      " [39 20 17  1  1  2]\n",
      " [21 15 10  3  1  1]\n",
      " [ 8 17  5  3  1  0]\n",
      " [ 3  2  0  0  0  0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.63      0.54       147\n",
      "           1       0.29      0.36      0.32        89\n",
      "           2       0.23      0.21      0.22        80\n",
      "           3       0.20      0.06      0.09        51\n",
      "           4       0.17      0.03      0.05        34\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.36       406\n",
      "   macro avg       0.23      0.21      0.20       406\n",
      "weighted avg       0.32      0.36      0.32       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for LDA\n",
    "lda_model.fit(X_train, y_train)\n",
    "lda_pred = lda_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for LDA:\\n')\n",
    "print(accuracy_score(y_test, lda_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, lda_pred), '\\n')\n",
    "print(classification_report(y_test, lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "leading-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for KNN:\n",
      "\n",
      "0.33498 \n",
      "\n",
      "[[102  20  21   4   0   0]\n",
      " [ 47  25  15   1   1   0]\n",
      " [ 47  22   9   2   0   0]\n",
      " [ 35  12   4   0   0   0]\n",
      " [ 17   9   4   4   0   0]\n",
      " [  3   1   0   1   0   0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.69      0.51       147\n",
      "           1       0.28      0.28      0.28        89\n",
      "           2       0.17      0.11      0.14        80\n",
      "           3       0.00      0.00      0.00        51\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.33       406\n",
      "   macro avg       0.14      0.18      0.15       406\n",
      "weighted avg       0.24      0.33      0.27       406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculating for kNN\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for KNN:\\n')\n",
    "print(accuracy_score(y_test, knn_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, knn_pred), '\\n')\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "invalid-candy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for CART:\n",
      "\n",
      "0.24631 \n",
      "\n",
      "[[54 31 40 16  6  0]\n",
      " [28 18 25 11  5  2]\n",
      " [32 15 20 10  2  1]\n",
      " [20 12 13  5  1  0]\n",
      " [13  9  6  3  3  0]\n",
      " [ 0  0  3  2  0  0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.37      0.37       147\n",
      "           1       0.21      0.20      0.21        89\n",
      "           2       0.19      0.25      0.21        80\n",
      "           3       0.11      0.10      0.10        51\n",
      "           4       0.18      0.09      0.12        34\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.25       406\n",
      "   macro avg       0.17      0.17      0.17       406\n",
      "weighted avg       0.24      0.25      0.24       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for CART\n",
    "cart_model.fit(X_train, y_train)\n",
    "cart_pred = cart_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for CART:\\n')\n",
    "print(accuracy_score(y_test, cart_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, cart_pred), '\\n')\n",
    "print(classification_report(y_test, cart_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "adjacent-triangle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for GNB:\n",
      "\n",
      "0.38177 \n",
      "\n",
      "[[108  19  20   0   0   0]\n",
      " [ 45  32  12   0   0   0]\n",
      " [ 47  18  15   0   0   0]\n",
      " [ 26  14  11   0   0   0]\n",
      " [ 12  19   3   0   0   0]\n",
      " [  3   2   0   0   0   0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.73      0.56       147\n",
      "           1       0.31      0.36      0.33        89\n",
      "           2       0.25      0.19      0.21        80\n",
      "           3       0.00      0.00      0.00        51\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.38       406\n",
      "   macro avg       0.17      0.21      0.18       406\n",
      "weighted avg       0.28      0.38      0.32       406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculating for GNB\n",
    "gnb_model.fit(X_train, y_train)\n",
    "gnb_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for GNB:\\n')\n",
    "print(accuracy_score(y_test, gnb_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, gnb_pred), '\\n')\n",
    "print(classification_report(y_test, gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "directed-terrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for SVM:\n",
      "\n",
      "0.38177 \n",
      "\n",
      "[[116  19  12   0   0   0]\n",
      " [ 55  27   7   0   0   0]\n",
      " [ 52  16  12   0   0   0]\n",
      " [ 36  12   3   0   0   0]\n",
      " [ 15  16   3   0   0   0]\n",
      " [  3   2   0   0   0   0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.79      0.55       147\n",
      "           1       0.29      0.30      0.30        89\n",
      "           2       0.32      0.15      0.21        80\n",
      "           3       0.00      0.00      0.00        51\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.38       406\n",
      "   macro avg       0.17      0.21      0.18       406\n",
      "weighted avg       0.28      0.38      0.30       406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Support Vector Machine\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for SVM:\\n')\n",
    "print(accuracy_score(y_test, svm_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, svm_pred), '\\n')\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "dynamic-choir",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for RFC:\n",
      "\n",
      "0.36207 \n",
      "\n",
      "[[106  21  20   0   0   0]\n",
      " [ 46  28  13   2   0   0]\n",
      " [ 47  20  13   0   0   0]\n",
      " [ 31  12   8   0   0   0]\n",
      " [ 14  17   2   1   0   0]\n",
      " [  1   2   2   0   0   0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.72      0.54       147\n",
      "           1       0.28      0.31      0.30        89\n",
      "           2       0.22      0.16      0.19        80\n",
      "           3       0.00      0.00      0.00        51\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.36       406\n",
      "   macro avg       0.16      0.20      0.17       406\n",
      "weighted avg       0.26      0.36      0.30       406\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Random Forest Classifier\n",
    "rfc_model.fit(X_train, y_train)\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for RFC:\\n')\n",
    "print(accuracy_score(y_test, rfc_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, rfc_pred), '\\n')\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "convinced-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Robust vs Non-Robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "civil-shipping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robust          368\n",
      "prefrail_mci    268\n",
      "prefrail        250\n",
      "mci             142\n",
      "frail_mci        86\n",
      "frail             9\n",
      "Name: condition, dtype: int64\n",
      "\n",
      "####################################################################\n",
      "Number of Rows of Dataframe:\n",
      "1123\n",
      "Number of Columns of Dataframe:\n",
      "59\n",
      "\n",
      "####################################################################\n",
      "Threshold for number of NULLs in a column: 0.1095\n",
      "Number of Columns before Parsing for Too Many NULLs in a column:\n",
      "59\n",
      "Number of Columns after Parsing for Too Many NULLs in a column:\n",
      "51\n",
      "\n",
      "Columns Removed:\n",
      "B1_b5\n",
      "B4_a1\n",
      "B4_a3\n",
      "B4_a4\n",
      "B4_a6\n",
      "B4_b1\n",
      "B4_b3\n",
      "B5_a1\n",
      "\n",
      "####################################################################\n",
      "Number of Columns after dropping A1_2, B1_b4, B2_c3, B4_b2 for inconsistent data types:\n",
      "47\n",
      "\n",
      "####################################################################\n",
      "Number of Rows before Parsing NULLs in data:\n",
      "1123\n",
      "Number of Rows after Parsing NULLs in data:\n",
      "1015\n"
     ]
    }
   ],
   "source": [
    "# Pre-parse the dataset\n",
    "data1 = preprocess(\"rawfile_blood.csv\")\n",
    "\n",
    "for i in range(0, len(data1)):\n",
    "\tif data1.at[i, 'condition'] == 'frail':\n",
    "\t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "\telif data1.at[i, 'condition'] == 'frail_mci':\n",
    "\t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "\telif data1.at[i, 'condition'] == 'mci':\n",
    "\t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "\telif data1.at[i, 'condition'] == 'prefrail_mci':\n",
    "\t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "\telif data1.at[i, 'condition'] == 'prefrail':\n",
    "\t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "\telif data1.at[i, 'condition'] == 'robust':\n",
    "\t\tdata1.at[i, 'condition'] = 'robust'\n",
    "\n",
    "# df1 = data1[data1.condition == 'frail_mci']\n",
    "# df1 = df1.reset_index(drop=True)\n",
    "\n",
    "# df2 = data1[data1.condition == 'robust']\n",
    "# df2 = df2.reset_index(drop=True)\n",
    "\n",
    "# data = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "relevant-husband",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-robust    672\n",
       "robust        343\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = data1['condition'].value_counts()\n",
    "condition = c.index\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "prompt-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME02646</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "      <td>46.5</td>\n",
       "      <td>121</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ME03109</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>55.6</td>\n",
       "      <td>142</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>87</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ME06997</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>20</td>\n",
       "      <td>76.8</td>\n",
       "      <td>105</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.023</td>\n",
       "      <td>2.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ME07149</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>16</td>\n",
       "      <td>47.2</td>\n",
       "      <td>122</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.06</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME07700</td>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>14</td>\n",
       "      <td>31.3</td>\n",
       "      <td>124</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "0  ME02646          0   196    24  46.5   121   3.93   0.37     95     31   \n",
       "1  ME03109          0   200    23  55.6   142   4.82   0.42     87     30   \n",
       "2  ME06997          0   441    20  76.8   105   4.54   0.41     90     30   \n",
       "3  ME07149          0   265    16  47.2   122   4.53   0.39     86     27   \n",
       "4  ME07700          0   425    14  31.3   124   4.44   0.38     85     28   \n",
       "\n",
       "   ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "0  ...      7     12     13      6  0.2    6.0  1.011   1.14    4.1  5.9  \n",
       "1  ...      7     20     17     26  3.1    5.0  1.011   3.25    4.6  8.5  \n",
       "2  ...      5     16     19     15  1.4    7.0  1.023   2.14    4.0  6.4  \n",
       "3  ...      8     24     19     21  2.1    5.5  1.012   1.06    4.7  6.1  \n",
       "4  ...      6     20     23     23  6.0    5.5  1.013   1.95    3.8  5.8  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(condition)):\n",
    "    data1['condition'].replace(condition[i], i, inplace = True)\n",
    "\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "genuine-implementation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>MV00454</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "      <td>19</td>\n",
       "      <td>67.5</td>\n",
       "      <td>138</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>MV00456</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>18</td>\n",
       "      <td>51.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>MV00460</td>\n",
       "      <td>1</td>\n",
       "      <td>418</td>\n",
       "      <td>17</td>\n",
       "      <td>61.0</td>\n",
       "      <td>122</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.005</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>MV00502</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>18</td>\n",
       "      <td>43.1</td>\n",
       "      <td>136</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>MV00510</td>\n",
       "      <td>1</td>\n",
       "      <td>371</td>\n",
       "      <td>24</td>\n",
       "      <td>55.9</td>\n",
       "      <td>127</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.017</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "1010  MV00454          1   220    19  67.5   138   4.66   0.42     91     30   \n",
       "1011  MV00456          1   334    18  51.0   139   4.63   0.42     91     30   \n",
       "1012  MV00460          1   418    17  61.0   122   4.18   0.38     90     29   \n",
       "1013  MV00502          1   393    18  43.1   136   4.57   0.43     94     30   \n",
       "1014  MV00510          1   371    24  55.9   127   4.41   0.40     90     29   \n",
       "\n",
       "      ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "1010  ...     20     10     17      8  6.6    7.0  1.015   1.29    4.5  6.2  \n",
       "1011  ...     16     22     35     40  1.0    6.0  1.015   1.88    3.9  5.6  \n",
       "1012  ...     19     20     23     15  0.4    6.5  1.005   3.58    4.0  5.6  \n",
       "1013  ...     13     11     22     23  0.7    7.0  1.009   0.92    4.1  6.0  \n",
       "1014  ...     13     14     16     12  7.5    8.0  1.017   2.45    4.5  6.2  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "exotic-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data1['condition']\n",
    "\n",
    "features = ['A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
    "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
    "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
    "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
    "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
    "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6']\n",
    "X_old = data1[features]\n",
    "\n",
    "X = X_old\n",
    "X = StandardScaler().fit_transform(X_old)\n",
    "X = MinMaxScaler().fit_transform(X_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "tight-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 672, 1: 343})"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "dutch-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample to balance the dataset\n",
    "\n",
    "# Set Sampling Strategy\n",
    "sampling_strategy = {0: 343, 1: 343}\n",
    "undersample = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "\n",
    "# Undersample\n",
    "X, y = undersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "informed-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 343, 1: 343})"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "executed-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOLDOUT METHOD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "inappropriate-treasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.604\n",
      "Linear Discriminant Analysis: 0.629\n",
      "K-Nearest Neigbors: 0.502\n",
      "Classification and Regression Trees: 0.545\n",
      "Gaussian Naive Bayes: 0.596\n",
      "Support Vector Machines: 0.607\n",
      "Random Forest Classifier: 0.647\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1)\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression:\", log_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train)\n",
    "print(\"Linear Discriminant Analysis:\", lda_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"K-Nearest Neigbors:\", knn_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X_train, y_train)\n",
    "print(\"Classification and Regression Trees:\", cart_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)\n",
    "print(\"Gaussian Naive Bayes:\", gnb_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(\"Support Vector Machines:\", svm_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train)\n",
    "print(\"Random Forest Classifier:\", rfc_model.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "suited-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "acute-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.58 accuracy with a standard deviation of 0.04\n",
      "Linear Discriminant Analysis: 0.60 accuracy with a standard deviation of 0.05\n",
      "K-Nearest Neighbors: 0.57 accuracy with a standard deviation of 0.03\n",
      "Classification and Regression Trees: 0.56 accuracy with a standard deviation of 0.03\n",
      "Gaussian Naive Bayes: 0.57 accuracy with a standard deviation of 0.02\n",
      "Support Vector Machines: 0.60 accuracy with a standard deviation of 0.02\n",
      "Random Forest Classifier: 0.59 accuracy with a standard deviation of 0.01\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X, y)\n",
    "scores = cross_val_score(log_model, X, y, cv=5)\n",
    "print(\"Logistic Regression: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X, y)\n",
    "scores = cross_val_score(lda_model, X, y, cv=5)\n",
    "print(\"Linear Discriminant Analysis: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5)\n",
    "print(\"K-Nearest Neighbors: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5)\n",
    "print(\"Classification and Regression Trees: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5)\n",
    "print(\"Gaussian Naive Bayes: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5)\n",
    "print(\"Support Vector Machines: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5)\n",
    "print(\"Random Forest Classifier: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "precious-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58        69\n",
      "           1       0.60      0.67      0.63        69\n",
      "\n",
      "    accuracy                           0.61       138\n",
      "   macro avg       0.61      0.61      0.61       138\n",
      "weighted avg       0.61      0.61      0.61       138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56        69\n",
      "           1       0.57      0.65      0.61        68\n",
      "\n",
      "    accuracy                           0.58       137\n",
      "   macro avg       0.59      0.58      0.58       137\n",
      "weighted avg       0.59      0.58      0.58       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.42      0.47        69\n",
      "           1       0.51      0.62      0.56        68\n",
      "\n",
      "    accuracy                           0.52       137\n",
      "   macro avg       0.52      0.52      0.51       137\n",
      "weighted avg       0.52      0.52      0.51       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59        68\n",
      "           1       0.59      0.59      0.59        69\n",
      "\n",
      "    accuracy                           0.59       137\n",
      "   macro avg       0.59      0.59      0.59       137\n",
      "weighted avg       0.59      0.59      0.59       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62        68\n",
      "           1       0.63      0.61      0.62        69\n",
      "\n",
      "    accuracy                           0.62       137\n",
      "   macro avg       0.62      0.62      0.62       137\n",
      "weighted avg       0.62      0.62      0.62       137\n",
      "\n",
      "[0.60869565 0.58394161 0.51824818 0.59124088 0.62043796]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "scores = cross_val_score(log_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "hundred-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.63        69\n",
      "           1       0.64      0.75      0.69        69\n",
      "\n",
      "    accuracy                           0.67       138\n",
      "   macro avg       0.67      0.67      0.66       138\n",
      "weighted avg       0.67      0.67      0.66       138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64        69\n",
      "           1       0.63      0.66      0.65        68\n",
      "\n",
      "    accuracy                           0.64       137\n",
      "   macro avg       0.64      0.64      0.64       137\n",
      "weighted avg       0.64      0.64      0.64       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52        69\n",
      "           1       0.54      0.63      0.59        68\n",
      "\n",
      "    accuracy                           0.55       137\n",
      "   macro avg       0.56      0.56      0.55       137\n",
      "weighted avg       0.56      0.55      0.55       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55        68\n",
      "           1       0.56      0.57      0.56        69\n",
      "\n",
      "    accuracy                           0.55       137\n",
      "   macro avg       0.55      0.55      0.55       137\n",
      "weighted avg       0.55      0.55      0.55       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.57      0.58        68\n",
      "           1       0.59      0.61      0.60        69\n",
      "\n",
      "    accuracy                           0.59       137\n",
      "   macro avg       0.59      0.59      0.59       137\n",
      "weighted avg       0.59      0.59      0.59       137\n",
      "\n",
      "[0.66666667 0.64233577 0.55474453 0.55474453 0.59124088]\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "scores = cross_val_score(lda_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "colored-gnome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53        69\n",
      "           1       0.56      0.67      0.61        69\n",
      "\n",
      "    accuracy                           0.57       138\n",
      "   macro avg       0.58      0.57      0.57       138\n",
      "weighted avg       0.58      0.57      0.57       138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.39      0.45        69\n",
      "           1       0.52      0.66      0.58        68\n",
      "\n",
      "    accuracy                           0.53       137\n",
      "   macro avg       0.53      0.53      0.52       137\n",
      "weighted avg       0.53      0.53      0.52       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.54      0.56        69\n",
      "           1       0.57      0.62      0.59        68\n",
      "\n",
      "    accuracy                           0.58       137\n",
      "   macro avg       0.58      0.58      0.58       137\n",
      "weighted avg       0.58      0.58      0.58       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.49      0.56        68\n",
      "           1       0.60      0.75      0.67        69\n",
      "\n",
      "    accuracy                           0.62       137\n",
      "   macro avg       0.63      0.62      0.61       137\n",
      "weighted avg       0.63      0.62      0.61       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.49      0.53        68\n",
      "           1       0.56      0.65      0.60        69\n",
      "\n",
      "    accuracy                           0.57       137\n",
      "   macro avg       0.57      0.57      0.57       137\n",
      "weighted avg       0.57      0.57      0.57       137\n",
      "\n",
      "[0.57246377 0.52554745 0.57664234 0.62043796 0.56934307]\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neigbors\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "internal-gothic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.52        69\n",
      "           1       0.51      0.48      0.49        69\n",
      "\n",
      "    accuracy                           0.51       138\n",
      "   macro avg       0.51      0.51      0.51       138\n",
      "weighted avg       0.51      0.51      0.51       138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.48        69\n",
      "           1       0.51      0.59      0.55        68\n",
      "\n",
      "    accuracy                           0.52       137\n",
      "   macro avg       0.52      0.52      0.52       137\n",
      "weighted avg       0.52      0.52      0.52       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.55      0.57        69\n",
      "           1       0.58      0.62      0.60        68\n",
      "\n",
      "    accuracy                           0.58       137\n",
      "   macro avg       0.58      0.58      0.58       137\n",
      "weighted avg       0.58      0.58      0.58       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.54      0.55        68\n",
      "           1       0.56      0.58      0.57        69\n",
      "\n",
      "    accuracy                           0.56       137\n",
      "   macro avg       0.56      0.56      0.56       137\n",
      "weighted avg       0.56      0.56      0.56       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.47        68\n",
      "           1       0.50      0.54      0.52        69\n",
      "\n",
      "    accuracy                           0.50       137\n",
      "   macro avg       0.50      0.50      0.50       137\n",
      "weighted avg       0.50      0.50      0.50       137\n",
      "\n",
      "[0.50724638 0.51824818 0.58394161 0.5620438  0.49635036]\n"
     ]
    }
   ],
   "source": [
    "# Classification and Regression Trees\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "descending-occupation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.30      0.42        69\n",
      "           1       0.56      0.87      0.68        69\n",
      "\n",
      "    accuracy                           0.59       138\n",
      "   macro avg       0.63      0.59      0.55       138\n",
      "weighted avg       0.63      0.59      0.55       138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.35      0.46        69\n",
      "           1       0.56      0.84      0.67        68\n",
      "\n",
      "    accuracy                           0.59       137\n",
      "   macro avg       0.62      0.59      0.57       137\n",
      "weighted avg       0.62      0.59      0.57       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.32      0.43        69\n",
      "           1       0.54      0.82      0.65        68\n",
      "\n",
      "    accuracy                           0.57       137\n",
      "   macro avg       0.60      0.57      0.54       137\n",
      "weighted avg       0.60      0.57      0.54       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.31      0.42        68\n",
      "           1       0.55      0.84      0.67        69\n",
      "\n",
      "    accuracy                           0.58       137\n",
      "   macro avg       0.60      0.57      0.54       137\n",
      "weighted avg       0.60      0.58      0.54       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.19      0.29        68\n",
      "           1       0.53      0.88      0.66        69\n",
      "\n",
      "    accuracy                           0.54       137\n",
      "   macro avg       0.57      0.54      0.48       137\n",
      "weighted avg       0.57      0.54      0.48       137\n",
      "\n",
      "[0.58695652 0.59124088 0.56934307 0.57664234 0.54014599]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "elegant-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56        69\n",
      "           1       0.59      0.70      0.64        69\n",
      "\n",
      "    accuracy                           0.60       138\n",
      "   macro avg       0.61      0.60      0.60       138\n",
      "weighted avg       0.61      0.60      0.60       138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.46      0.54        69\n",
      "           1       0.57      0.74      0.65        68\n",
      "\n",
      "    accuracy                           0.60       137\n",
      "   macro avg       0.61      0.60      0.59       137\n",
      "weighted avg       0.61      0.60      0.59       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.41      0.49        69\n",
      "           1       0.55      0.75      0.64        68\n",
      "\n",
      "    accuracy                           0.58       137\n",
      "   macro avg       0.59      0.58      0.56       137\n",
      "weighted avg       0.59      0.58      0.56       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        68\n",
      "           1       0.62      0.74      0.68        69\n",
      "\n",
      "    accuracy                           0.64       137\n",
      "   macro avg       0.65      0.64      0.64       137\n",
      "weighted avg       0.65      0.64      0.64       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58        68\n",
      "           1       0.60      0.67      0.63        69\n",
      "\n",
      "    accuracy                           0.61       137\n",
      "   macro avg       0.61      0.61      0.60       137\n",
      "weighted avg       0.61      0.61      0.60       137\n",
      "\n",
      "[0.60144928 0.59854015 0.57664234 0.64233577 0.60583942]\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "brown-yacht",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59        69\n",
      "           1       0.59      0.58      0.58        69\n",
      "\n",
      "    accuracy                           0.59       138\n",
      "   macro avg       0.59      0.59      0.59       138\n",
      "weighted avg       0.59      0.59      0.59       138\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63        69\n",
      "           1       0.63      0.62      0.62        68\n",
      "\n",
      "    accuracy                           0.63       137\n",
      "   macro avg       0.63      0.63      0.63       137\n",
      "weighted avg       0.63      0.63      0.63       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62        69\n",
      "           1       0.62      0.62      0.62        68\n",
      "\n",
      "    accuracy                           0.62       137\n",
      "   macro avg       0.62      0.62      0.62       137\n",
      "weighted avg       0.62      0.62      0.62       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59        68\n",
      "           1       0.59      0.59      0.59        69\n",
      "\n",
      "    accuracy                           0.59       137\n",
      "   macro avg       0.59      0.59      0.59       137\n",
      "weighted avg       0.59      0.59      0.59       137\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57        68\n",
      "           1       0.58      0.61      0.60        69\n",
      "\n",
      "    accuracy                           0.58       137\n",
      "   macro avg       0.58      0.58      0.58       137\n",
      "weighted avg       0.58      0.58      0.58       137\n",
      "\n",
      "[0.58695652 0.62773723 0.62043796 0.59124088 0.58394161]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "essential-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Performance Metrics for Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "descending-renaissance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for Logistic Regression:\n",
      "\n",
      "0.60364 \n",
      "\n",
      "[[78 50]\n",
      " [59 88]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59       128\n",
      "           1       0.64      0.60      0.62       147\n",
      "\n",
      "    accuracy                           0.60       275\n",
      "   macro avg       0.60      0.60      0.60       275\n",
      "weighted avg       0.61      0.60      0.60       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Logistic Regression\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for Logistic Regression:\\n')\n",
    "print(accuracy_score(y_test, log_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, log_pred), '\\n')\n",
    "print(classification_report(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "flexible-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for LDA:\n",
      "\n",
      "0.62909 \n",
      "\n",
      "[[84 44]\n",
      " [58 89]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62       128\n",
      "           1       0.67      0.61      0.64       147\n",
      "\n",
      "    accuracy                           0.63       275\n",
      "   macro avg       0.63      0.63      0.63       275\n",
      "weighted avg       0.63      0.63      0.63       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for LDA\n",
    "lda_model.fit(X_train, y_train)\n",
    "lda_pred = lda_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for LDA:\\n')\n",
    "print(accuracy_score(y_test, lda_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, lda_pred), '\\n')\n",
    "print(classification_report(y_test, lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "different-coordinator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for KNN:\n",
      "\n",
      "0.50182 \n",
      "\n",
      "[[49 79]\n",
      " [58 89]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.42       128\n",
      "           1       0.53      0.61      0.57       147\n",
      "\n",
      "    accuracy                           0.50       275\n",
      "   macro avg       0.49      0.49      0.49       275\n",
      "weighted avg       0.50      0.50      0.50       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for kNN\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for KNN:\\n')\n",
    "print(accuracy_score(y_test, knn_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, knn_pred), '\\n')\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "moved-bristol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for CART:\n",
      "\n",
      "0.54909 \n",
      "\n",
      "[[63 65]\n",
      " [59 88]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.49      0.50       128\n",
      "           1       0.58      0.60      0.59       147\n",
      "\n",
      "    accuracy                           0.55       275\n",
      "   macro avg       0.55      0.55      0.55       275\n",
      "weighted avg       0.55      0.55      0.55       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for CART\n",
    "cart_model.fit(X_train, y_train)\n",
    "cart_pred = cart_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for CART:\\n')\n",
    "print(accuracy_score(y_test, cart_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, cart_pred), '\\n')\n",
    "print(classification_report(y_test, cart_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "retired-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for GNB:\n",
      "\n",
      "0.60364 \n",
      "\n",
      "[[78 50]\n",
      " [59 88]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59       128\n",
      "           1       0.64      0.60      0.62       147\n",
      "\n",
      "    accuracy                           0.60       275\n",
      "   macro avg       0.60      0.60      0.60       275\n",
      "weighted avg       0.61      0.60      0.60       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for GNB\n",
    "gnb_model.fit(X_train, y_train)\n",
    "gnb_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for GNB:\\n')\n",
    "print(accuracy_score(y_test, gnb_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, gnb_pred), '\\n')\n",
    "print(classification_report(y_test, gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "electric-breakfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for SVM:\n",
      "\n",
      "0.60727 \n",
      "\n",
      "[[68 60]\n",
      " [48 99]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56       128\n",
      "           1       0.62      0.67      0.65       147\n",
      "\n",
      "    accuracy                           0.61       275\n",
      "   macro avg       0.60      0.60      0.60       275\n",
      "weighted avg       0.61      0.61      0.61       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Support Vector Machine\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for SVM:\\n')\n",
    "print(accuracy_score(y_test, svm_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, svm_pred), '\\n')\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "right-reform",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for RFC:\n",
      "\n",
      "0.64364 \n",
      "\n",
      "[[85 43]\n",
      " [55 92]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63       128\n",
      "           1       0.68      0.63      0.65       147\n",
      "\n",
      "    accuracy                           0.64       275\n",
      "   macro avg       0.64      0.64      0.64       275\n",
      "weighted avg       0.65      0.64      0.64       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Random Forest Classifier\n",
    "rfc_model.fit(X_train, y_train)\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for RFC:\\n')\n",
    "print(accuracy_score(y_test, rfc_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, rfc_pred), '\\n')\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "electric-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Robust vs Frail + MCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "qualified-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robust          368\n",
      "prefrail_mci    268\n",
      "prefrail        250\n",
      "mci             142\n",
      "frail_mci        86\n",
      "frail             9\n",
      "Name: condition, dtype: int64\n",
      "\n",
      "####################################################################\n",
      "Number of Rows of Dataframe:\n",
      "1123\n",
      "Number of Columns of Dataframe:\n",
      "59\n",
      "\n",
      "####################################################################\n",
      "Threshold for number of NULLs in a column: 0.1095\n",
      "Number of Columns before Parsing for Too Many NULLs in a column:\n",
      "59\n",
      "Number of Columns after Parsing for Too Many NULLs in a column:\n",
      "51\n",
      "\n",
      "Columns Removed:\n",
      "B1_b5\n",
      "B4_a1\n",
      "B4_a3\n",
      "B4_a4\n",
      "B4_a6\n",
      "B4_b1\n",
      "B4_b3\n",
      "B5_a1\n",
      "\n",
      "####################################################################\n",
      "Number of Columns after dropping A1_2, B1_b4, B2_c3, B4_b2 for inconsistent data types:\n",
      "47\n",
      "\n",
      "####################################################################\n",
      "Number of Rows before Parsing NULLs in data:\n",
      "1123\n",
      "Number of Rows after Parsing NULLs in data:\n",
      "1015\n"
     ]
    }
   ],
   "source": [
    "# Pre-parse the dataset\n",
    "data2 = preprocess(\"rawfile_blood.csv\")\n",
    "\n",
    "# for i in range(0, len(data1)):\n",
    "# \tif data1.at[i, 'condition'] == 'frail':\n",
    "# \t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data1.at[i, 'condition'] == 'frail_mci':\n",
    "# \t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data1.at[i, 'condition'] == 'mci':\n",
    "# \t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data1.at[i, 'condition'] == 'prefrail_mci':\n",
    "# \t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data1.at[i, 'condition'] == 'prefrail':\n",
    "# \t\tdata1.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data1.at[i, 'condition'] == 'robust':\n",
    "# \t\tdata1.at[i, 'condition'] = 'robust'\n",
    "\n",
    "df1 = data2[data2.condition == 'frail_mci']\n",
    "df1 = df1.reset_index(drop=True)\n",
    "\n",
    "df2 = data2[data2.condition == 'robust']\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "data2 = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "primary-employment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "robust       343\n",
       "frail_mci     76\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = data2['condition'].value_counts()\n",
    "condition = c.index\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "timely-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME01378</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>20</td>\n",
       "      <td>33.5</td>\n",
       "      <td>150</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ME02832</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>16</td>\n",
       "      <td>87.0</td>\n",
       "      <td>134</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.40</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>13.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ME02909</td>\n",
       "      <td>1</td>\n",
       "      <td>1476</td>\n",
       "      <td>16</td>\n",
       "      <td>57.0</td>\n",
       "      <td>119</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.36</td>\n",
       "      <td>94</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ME02998</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>18</td>\n",
       "      <td>63.8</td>\n",
       "      <td>135</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.42</td>\n",
       "      <td>86</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>16.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.017</td>\n",
       "      <td>1.32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME03061</td>\n",
       "      <td>1</td>\n",
       "      <td>287</td>\n",
       "      <td>20</td>\n",
       "      <td>95.5</td>\n",
       "      <td>146</td>\n",
       "      <td>5.18</td>\n",
       "      <td>0.44</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.006</td>\n",
       "      <td>2.94</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "0  ME01378          1   241    20  33.5   150   5.25   0.46     87     29   \n",
       "1  ME02832          1   444    16  87.0   134   4.65   0.40     85     28   \n",
       "2  ME02909          1  1476    16  57.0   119   3.80   0.36     94     31   \n",
       "3  ME02998          1   339    18  63.8   135   4.89   0.42     86     28   \n",
       "4  ME03061          1   287    20  95.5   146   5.18   0.44     85     28   \n",
       "\n",
       "   ...  B2_d6  B2_d7  B2_d8  B2_d9    B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "0  ...     10     21     22     17   1.3    7.0  1.010   0.69    4.7  5.9  \n",
       "1  ...     10     14     20     15  13.4    6.0  1.005   1.29    4.5  5.8  \n",
       "2  ...     18     17     35     21   0.2    7.5  1.012   1.90    4.1  5.8  \n",
       "3  ...     13     16     25     13  16.8    5.0  1.017   1.32    4.0  6.0  \n",
       "4  ...     18     22     25     24   1.4    7.5  1.006   2.94    4.6  6.1  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(condition)):\n",
    "    data2['condition'].replace(condition[i], i, inplace = True)\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "worse-meaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>MV00454</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>19</td>\n",
       "      <td>67.5</td>\n",
       "      <td>138</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>MV00456</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>18</td>\n",
       "      <td>51.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>MV00460</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>17</td>\n",
       "      <td>61.0</td>\n",
       "      <td>122</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.005</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>MV00502</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>18</td>\n",
       "      <td>43.1</td>\n",
       "      <td>136</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>MV00510</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>24</td>\n",
       "      <td>55.9</td>\n",
       "      <td>127</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.017</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "414  MV00454          0   220    19  67.5   138   4.66   0.42     91     30   \n",
       "415  MV00456          0   334    18  51.0   139   4.63   0.42     91     30   \n",
       "416  MV00460          0   418    17  61.0   122   4.18   0.38     90     29   \n",
       "417  MV00502          0   393    18  43.1   136   4.57   0.43     94     30   \n",
       "418  MV00510          0   371    24  55.9   127   4.41   0.40     90     29   \n",
       "\n",
       "     ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "414  ...     20     10     17      8  6.6    7.0  1.015   1.29    4.5  6.2  \n",
       "415  ...     16     22     35     40  1.0    6.0  1.015   1.88    3.9  5.6  \n",
       "416  ...     19     20     23     15  0.4    6.5  1.005   3.58    4.0  5.6  \n",
       "417  ...     13     11     22     23  0.7    7.0  1.009   0.92    4.1  6.0  \n",
       "418  ...     13     14     16     12  7.5    8.0  1.017   2.45    4.5  6.2  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "raising-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2['condition']\n",
    "\n",
    "features = ['A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
    "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
    "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
    "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
    "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
    "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6']\n",
    "X_old = data2[features]\n",
    "\n",
    "X = X_old\n",
    "X = StandardScaler().fit_transform(X_old)\n",
    "X = MinMaxScaler().fit_transform(X_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "outer-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 76, 0: 343})"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "wrong-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample to balance the dataset\n",
    "\n",
    "# Set Sampling Strategy\n",
    "sampling_strategy = {0: 76, 1: 76}\n",
    "undersample = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "\n",
    "# Undersample\n",
    "X, y = undersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "requested-sixth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 76, 1: 76})"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "unexpected-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOLDOUT METHOD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "derived-export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.607\n",
      "Linear Discriminant Analysis: 0.59\n",
      "K-Nearest Neigbors: 0.492\n",
      "Classification and Regression Trees: 0.59\n",
      "Gaussian Naive Bayes: 0.705\n",
      "Support Vector Machines: 0.557\n",
      "Random Forest Classifier: 0.639\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1)\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression:\", log_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train)\n",
    "print(\"Linear Discriminant Analysis:\", lda_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"K-Nearest Neigbors:\", knn_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X_train, y_train)\n",
    "print(\"Classification and Regression Trees:\", cart_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)\n",
    "print(\"Gaussian Naive Bayes:\", gnb_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(\"Support Vector Machines:\", svm_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train)\n",
    "print(\"Random Forest Classifier:\", rfc_model.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "sitting-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "gothic-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.72 accuracy with a standard deviation of 0.08\n",
      "Linear Discriminant Analysis: 0.69 accuracy with a standard deviation of 0.04\n",
      "K-Nearest Neighbors: 0.65 accuracy with a standard deviation of 0.05\n",
      "Classification and Regression Trees: 0.60 accuracy with a standard deviation of 0.05\n",
      "Gaussian Naive Bayes: 0.74 accuracy with a standard deviation of 0.07\n",
      "Support Vector Machines: 0.73 accuracy with a standard deviation of 0.08\n",
      "Random Forest Classifier: 0.68 accuracy with a standard deviation of 0.10\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X, y)\n",
    "scores = cross_val_score(log_model, X, y, cv=5)\n",
    "print(\"Logistic Regression: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X, y)\n",
    "scores = cross_val_score(lda_model, X, y, cv=5)\n",
    "print(\"Linear Discriminant Analysis: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5)\n",
    "print(\"K-Nearest Neighbors: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5)\n",
    "print(\"Classification and Regression Trees: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5)\n",
    "print(\"Gaussian Naive Bayes: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5)\n",
    "print(\"Support Vector Machines: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5)\n",
    "print(\"Random Forest Classifier: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "supposed-hamilton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73        16\n",
      "           1       0.71      0.80      0.75        15\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.75      0.74      0.74        31\n",
      "weighted avg       0.75      0.74      0.74        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        15\n",
      "           1       1.00      0.69      0.81        16\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.88      0.84      0.84        31\n",
      "weighted avg       0.88      0.84      0.84        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57        15\n",
      "           1       0.59      0.67      0.62        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71        15\n",
      "           1       0.71      0.67      0.69        15\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.70      0.70      0.70        30\n",
      "weighted avg       0.70      0.70      0.70        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        15\n",
      "           1       0.77      0.67      0.71        15\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.74      0.73      0.73        30\n",
      "weighted avg       0.74      0.73      0.73        30\n",
      "\n",
      "[0.74193548 0.83870968 0.6        0.7        0.73333333]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "scores = cross_val_score(log_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "legal-arizona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67        16\n",
      "           1       0.65      0.73      0.69        15\n",
      "\n",
      "    accuracy                           0.68        31\n",
      "   macro avg       0.68      0.68      0.68        31\n",
      "weighted avg       0.68      0.68      0.68        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.71        15\n",
      "           1       0.75      0.56      0.64        16\n",
      "\n",
      "    accuracy                           0.68        31\n",
      "   macro avg       0.69      0.68      0.67        31\n",
      "weighted avg       0.69      0.68      0.67        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69        15\n",
      "           1       0.69      0.60      0.64        15\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.67      0.67      0.67        30\n",
      "weighted avg       0.67      0.67      0.67        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        15\n",
      "           1       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.77        30\n",
      "   macro avg       0.78      0.77      0.76        30\n",
      "weighted avg       0.78      0.77      0.76        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64        15\n",
      "           1       0.65      0.73      0.69        15\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.67      0.67      0.67        30\n",
      "weighted avg       0.67      0.67      0.67        30\n",
      "\n",
      "[0.67741935 0.67741935 0.66666667 0.76666667 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "scores = cross_val_score(lda_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "curious-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.88      0.72        16\n",
      "           1       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.65        31\n",
      "   macro avg       0.68      0.64      0.62        31\n",
      "weighted avg       0.68      0.65      0.62        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.68        15\n",
      "           1       0.75      0.38      0.50        16\n",
      "\n",
      "    accuracy                           0.61        31\n",
      "   macro avg       0.66      0.62      0.59        31\n",
      "weighted avg       0.66      0.61      0.59        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.62        15\n",
      "           1       0.62      0.53      0.57        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.72        15\n",
      "           1       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.70      0.67      0.65        30\n",
      "weighted avg       0.70      0.67      0.65        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75        15\n",
      "           1       0.77      0.67      0.71        15\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.74      0.73      0.73        30\n",
      "weighted avg       0.74      0.73      0.73        30\n",
      "\n",
      "[0.64516129 0.61290323 0.6        0.66666667 0.73333333]\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neigbors\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "unlimited-fantasy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.75      0.69        16\n",
      "           1       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.65        31\n",
      "   macro avg       0.65      0.64      0.64        31\n",
      "weighted avg       0.65      0.65      0.64        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.60      0.56        15\n",
      "           1       0.57      0.50      0.53        16\n",
      "\n",
      "    accuracy                           0.55        31\n",
      "   macro avg       0.55      0.55      0.55        31\n",
      "weighted avg       0.55      0.55      0.55        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65        15\n",
      "           1       0.64      0.60      0.62        15\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.63      0.63      0.63        30\n",
      "weighted avg       0.63      0.63      0.63        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65        15\n",
      "           1       0.64      0.60      0.62        15\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.63      0.63      0.63        30\n",
      "weighted avg       0.63      0.63      0.63        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        15\n",
      "           1       0.60      0.60      0.60        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "[0.64516129 0.5483871  0.63333333 0.63333333 0.6       ]\n"
     ]
    }
   ],
   "source": [
    "# Classification and Regression Trees\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "musical-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        16\n",
      "           1       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.81      0.81      0.81        31\n",
      "weighted avg       0.81      0.81      0.81        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80        15\n",
      "           1       0.91      0.62      0.74        16\n",
      "\n",
      "    accuracy                           0.77        31\n",
      "   macro avg       0.80      0.78      0.77        31\n",
      "weighted avg       0.81      0.77      0.77        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69        15\n",
      "           1       0.69      0.60      0.64        15\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.67      0.67      0.67        30\n",
      "weighted avg       0.67      0.67      0.67        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        15\n",
      "           1       1.00      0.60      0.75        15\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.86      0.80      0.79        30\n",
      "weighted avg       0.86      0.80      0.79        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.69        15\n",
      "           1       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.65      0.63      0.62        30\n",
      "weighted avg       0.65      0.63      0.62        30\n",
      "\n",
      "[0.80645161 0.77419355 0.66666667 0.8        0.63333333]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "illegal-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        16\n",
      "           1       0.73      0.73      0.73        15\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.74      0.74      0.74        31\n",
      "weighted avg       0.74      0.74      0.74        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        15\n",
      "           1       1.00      0.69      0.81        16\n",
      "\n",
      "    accuracy                           0.84        31\n",
      "   macro avg       0.88      0.84      0.84        31\n",
      "weighted avg       0.88      0.84      0.84        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        15\n",
      "           1       0.60      0.60      0.60        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        15\n",
      "           1       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.77        30\n",
      "   macro avg       0.78      0.77      0.76        30\n",
      "weighted avg       0.78      0.77      0.76        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71        15\n",
      "           1       0.71      0.67      0.69        15\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.70      0.70      0.70        30\n",
      "weighted avg       0.70      0.70      0.70        30\n",
      "\n",
      "[0.74193548 0.83870968 0.6        0.76666667 0.7       ]\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "formed-difference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74        16\n",
      "           1       0.75      0.60      0.67        15\n",
      "\n",
      "    accuracy                           0.71        31\n",
      "   macro avg       0.72      0.71      0.70        31\n",
      "weighted avg       0.72      0.71      0.71        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        15\n",
      "           1       1.00      0.50      0.67        16\n",
      "\n",
      "    accuracy                           0.74        31\n",
      "   macro avg       0.83      0.75      0.73        31\n",
      "weighted avg       0.83      0.74      0.73        31\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        15\n",
      "           1       0.60      0.60      0.60        15\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.60      0.60      0.60        30\n",
      "weighted avg       0.60      0.60      0.60        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        15\n",
      "           1       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.80      0.80      0.80        30\n",
      "weighted avg       0.80      0.80      0.80        30\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        15\n",
      "           1       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.77        30\n",
      "   macro avg       0.78      0.77      0.76        30\n",
      "weighted avg       0.78      0.77      0.76        30\n",
      "\n",
      "[0.70967742 0.74193548 0.6        0.8        0.76666667]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "understanding-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Performance Metrics for Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "baking-gentleman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for Logistic Regression:\n",
      "\n",
      "0.60656 \n",
      "\n",
      "[[21  9]\n",
      " [15 16]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.64        30\n",
      "           1       0.64      0.52      0.57        31\n",
      "\n",
      "    accuracy                           0.61        61\n",
      "   macro avg       0.61      0.61      0.60        61\n",
      "weighted avg       0.61      0.61      0.60        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Logistic Regression\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for Logistic Regression:\\n')\n",
    "print(accuracy_score(y_test, log_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, log_pred), '\\n')\n",
    "print(classification_report(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "stunning-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for LDA:\n",
      "\n",
      "0.59016 \n",
      "\n",
      "[[21  9]\n",
      " [16 15]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.70      0.63        30\n",
      "           1       0.62      0.48      0.55        31\n",
      "\n",
      "    accuracy                           0.59        61\n",
      "   macro avg       0.60      0.59      0.59        61\n",
      "weighted avg       0.60      0.59      0.59        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for LDA\n",
    "lda_model.fit(X_train, y_train)\n",
    "lda_pred = lda_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for LDA:\\n')\n",
    "print(accuracy_score(y_test, lda_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, lda_pred), '\\n')\n",
    "print(classification_report(y_test, lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "sustained-greensboro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for KNN:\n",
      "\n",
      "0.4918 \n",
      "\n",
      "[[19 11]\n",
      " [20 11]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.63      0.55        30\n",
      "           1       0.50      0.35      0.42        31\n",
      "\n",
      "    accuracy                           0.49        61\n",
      "   macro avg       0.49      0.49      0.48        61\n",
      "weighted avg       0.49      0.49      0.48        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for kNN\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for KNN:\\n')\n",
    "print(accuracy_score(y_test, knn_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, knn_pred), '\\n')\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "cardiovascular-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for CART:\n",
      "\n",
      "0.5082 \n",
      "\n",
      "[[17 13]\n",
      " [17 14]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.57      0.53        30\n",
      "           1       0.52      0.45      0.48        31\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.51      0.51      0.51        61\n",
      "weighted avg       0.51      0.51      0.51        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for CART\n",
    "cart_model.fit(X_train, y_train)\n",
    "cart_pred = cart_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for CART:\\n')\n",
    "print(accuracy_score(y_test, cart_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, cart_pred), '\\n')\n",
    "print(classification_report(y_test, cart_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "concerned-union",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for GNB:\n",
      "\n",
      "0.60656 \n",
      "\n",
      "[[21  9]\n",
      " [15 16]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.64        30\n",
      "           1       0.64      0.52      0.57        31\n",
      "\n",
      "    accuracy                           0.61        61\n",
      "   macro avg       0.61      0.61      0.60        61\n",
      "weighted avg       0.61      0.61      0.60        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for GNB\n",
    "gnb_model.fit(X_train, y_train)\n",
    "gnb_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for GNB:\\n')\n",
    "print(accuracy_score(y_test, gnb_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, gnb_pred), '\\n')\n",
    "print(classification_report(y_test, gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "comfortable-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for SVM:\n",
      "\n",
      "0.55738 \n",
      "\n",
      "[[21  9]\n",
      " [18 13]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.70      0.61        30\n",
      "           1       0.59      0.42      0.49        31\n",
      "\n",
      "    accuracy                           0.56        61\n",
      "   macro avg       0.56      0.56      0.55        61\n",
      "weighted avg       0.57      0.56      0.55        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Support Vector Machine\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for SVM:\\n')\n",
    "print(accuracy_score(y_test, svm_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, svm_pred), '\\n')\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "normal-lloyd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for RFC:\n",
      "\n",
      "0.65574 \n",
      "\n",
      "[[21  9]\n",
      " [12 19]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67        30\n",
      "           1       0.68      0.61      0.64        31\n",
      "\n",
      "    accuracy                           0.66        61\n",
      "   macro avg       0.66      0.66      0.66        61\n",
      "weighted avg       0.66      0.66      0.66        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Random Forest Classifier\n",
    "rfc_model.fit(X_train, y_train)\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for RFC:\\n')\n",
    "print(accuracy_score(y_test, rfc_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, rfc_pred), '\\n')\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "hawaiian-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robust          368\n",
      "prefrail_mci    268\n",
      "prefrail        250\n",
      "mci             142\n",
      "frail_mci        86\n",
      "frail             9\n",
      "Name: condition, dtype: int64\n",
      "\n",
      "####################################################################\n",
      "Number of Rows of Dataframe:\n",
      "1123\n",
      "Number of Columns of Dataframe:\n",
      "59\n",
      "\n",
      "####################################################################\n",
      "Threshold for number of NULLs in a column: 0.1095\n",
      "Number of Columns before Parsing for Too Many NULLs in a column:\n",
      "59\n",
      "Number of Columns after Parsing for Too Many NULLs in a column:\n",
      "51\n",
      "\n",
      "Columns Removed:\n",
      "B1_b5\n",
      "B4_a1\n",
      "B4_a3\n",
      "B4_a4\n",
      "B4_a6\n",
      "B4_b1\n",
      "B4_b3\n",
      "B5_a1\n",
      "\n",
      "####################################################################\n",
      "Number of Columns after dropping A1_2, B1_b4, B2_c3, B4_b2 for inconsistent data types:\n",
      "47\n",
      "\n",
      "####################################################################\n",
      "Number of Rows before Parsing NULLs in data:\n",
      "1123\n",
      "Number of Rows after Parsing NULLs in data:\n",
      "1015\n"
     ]
    }
   ],
   "source": [
    "# Pre-parse the dataset\n",
    "data3 = preprocess(\"rawfile_blood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "fluid-carrier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME02646</td>\n",
       "      <td>frail</td>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "      <td>46.5</td>\n",
       "      <td>121</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ME03109</td>\n",
       "      <td>frail</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>55.6</td>\n",
       "      <td>142</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>87</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ME06997</td>\n",
       "      <td>frail</td>\n",
       "      <td>441</td>\n",
       "      <td>20</td>\n",
       "      <td>76.8</td>\n",
       "      <td>105</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.023</td>\n",
       "      <td>2.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ME07149</td>\n",
       "      <td>frail</td>\n",
       "      <td>265</td>\n",
       "      <td>16</td>\n",
       "      <td>47.2</td>\n",
       "      <td>122</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.06</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME07700</td>\n",
       "      <td>frail</td>\n",
       "      <td>425</td>\n",
       "      <td>14</td>\n",
       "      <td>31.3</td>\n",
       "      <td>124</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mtag condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  ...  \\\n",
       "0  ME02646     frail   196    24  46.5   121   3.93   0.37     95     31  ...   \n",
       "1  ME03109     frail   200    23  55.6   142   4.82   0.42     87     30  ...   \n",
       "2  ME06997     frail   441    20  76.8   105   4.54   0.41     90     30  ...   \n",
       "3  ME07149     frail   265    16  47.2   122   4.53   0.39     86     27  ...   \n",
       "4  ME07700     frail   425    14  31.3   124   4.44   0.38     85     28  ...   \n",
       "\n",
       "   B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "0      7     12     13      6  0.2    6.0  1.011   1.14    4.1  5.9  \n",
       "1      7     20     17     26  3.1    5.0  1.011   3.25    4.6  8.5  \n",
       "2      5     16     19     15  1.4    7.0  1.023   2.14    4.0  6.4  \n",
       "3      8     24     19     21  2.1    5.5  1.012   1.06    4.7  6.1  \n",
       "4      6     20     23     23  6.0    5.5  1.013   1.95    3.8  5.8  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "tutorial-choir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mtag', 'condition', 'A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
       "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
       "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
       "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
       "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
       "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "assigned-roads",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "robust          343\n",
       "prefrail_mci    233\n",
       "prefrail        223\n",
       "mci             133\n",
       "frail_mci        76\n",
       "frail             7\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = data3['condition'].value_counts()\n",
    "condition = c.index\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "victorian-ceremony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ME02646</td>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>24</td>\n",
       "      <td>46.5</td>\n",
       "      <td>121</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.14</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ME03109</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>55.6</td>\n",
       "      <td>142</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>87</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.011</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ME06997</td>\n",
       "      <td>5</td>\n",
       "      <td>441</td>\n",
       "      <td>20</td>\n",
       "      <td>76.8</td>\n",
       "      <td>105</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.023</td>\n",
       "      <td>2.14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ME07149</td>\n",
       "      <td>5</td>\n",
       "      <td>265</td>\n",
       "      <td>16</td>\n",
       "      <td>47.2</td>\n",
       "      <td>122</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.012</td>\n",
       "      <td>1.06</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ME07700</td>\n",
       "      <td>5</td>\n",
       "      <td>425</td>\n",
       "      <td>14</td>\n",
       "      <td>31.3</td>\n",
       "      <td>124</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "0  ME02646          5   196    24  46.5   121   3.93   0.37     95     31   \n",
       "1  ME03109          5   200    23  55.6   142   4.82   0.42     87     30   \n",
       "2  ME06997          5   441    20  76.8   105   4.54   0.41     90     30   \n",
       "3  ME07149          5   265    16  47.2   122   4.53   0.39     86     27   \n",
       "4  ME07700          5   425    14  31.3   124   4.44   0.38     85     28   \n",
       "\n",
       "   ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "0  ...      7     12     13      6  0.2    6.0  1.011   1.14    4.1  5.9  \n",
       "1  ...      7     20     17     26  3.1    5.0  1.011   3.25    4.6  8.5  \n",
       "2  ...      5     16     19     15  1.4    7.0  1.023   2.14    4.0  6.4  \n",
       "3  ...      8     24     19     21  2.1    5.5  1.012   1.06    4.7  6.1  \n",
       "4  ...      6     20     23     23  6.0    5.5  1.013   1.95    3.8  5.8  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(condition)):\n",
    "    data3['condition'].replace(condition[i], i, inplace = True)\n",
    "\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "alpha-generic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtag</th>\n",
       "      <th>condition</th>\n",
       "      <th>A1_1</th>\n",
       "      <th>A2_1</th>\n",
       "      <th>A3_1</th>\n",
       "      <th>B1_a</th>\n",
       "      <th>B1_a1</th>\n",
       "      <th>B1_a2</th>\n",
       "      <th>B1_a3</th>\n",
       "      <th>B1_a4</th>\n",
       "      <th>...</th>\n",
       "      <th>B2_d6</th>\n",
       "      <th>B2_d7</th>\n",
       "      <th>B2_d8</th>\n",
       "      <th>B2_d9</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4_a2</th>\n",
       "      <th>B4_a5</th>\n",
       "      <th>B5_a2</th>\n",
       "      <th>B5_a3</th>\n",
       "      <th>B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>MV00454</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>19</td>\n",
       "      <td>67.5</td>\n",
       "      <td>138</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>MV00456</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>18</td>\n",
       "      <td>51.0</td>\n",
       "      <td>139</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.42</td>\n",
       "      <td>91</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>MV00460</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>17</td>\n",
       "      <td>61.0</td>\n",
       "      <td>122</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.005</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>MV00502</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>18</td>\n",
       "      <td>43.1</td>\n",
       "      <td>136</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>MV00510</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "      <td>24</td>\n",
       "      <td>55.9</td>\n",
       "      <td>127</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.017</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mtag  condition  A1_1  A2_1  A3_1  B1_a  B1_a1  B1_a2  B1_a3  B1_a4  \\\n",
       "1010  MV00454          0   220    19  67.5   138   4.66   0.42     91     30   \n",
       "1011  MV00456          0   334    18  51.0   139   4.63   0.42     91     30   \n",
       "1012  MV00460          0   418    17  61.0   122   4.18   0.38     90     29   \n",
       "1013  MV00502          0   393    18  43.1   136   4.57   0.43     94     30   \n",
       "1014  MV00510          0   371    24  55.9   127   4.41   0.40     90     29   \n",
       "\n",
       "      ...  B2_d6  B2_d7  B2_d8  B2_d9   B3  B4_a2  B4_a5  B5_a2  B5_a3   B6  \n",
       "1010  ...     20     10     17      8  6.6    7.0  1.015   1.29    4.5  6.2  \n",
       "1011  ...     16     22     35     40  1.0    6.0  1.015   1.88    3.9  5.6  \n",
       "1012  ...     19     20     23     15  0.4    6.5  1.005   3.58    4.0  5.6  \n",
       "1013  ...     13     11     22     23  0.7    7.0  1.009   0.92    4.1  6.0  \n",
       "1014  ...     13     14     16     12  7.5    8.0  1.017   2.45    4.5  6.2  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "returning-egypt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mtag', 'condition', 'A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
       "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
       "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
       "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
       "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
       "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "manufactured-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data3['condition']\n",
    "\n",
    "features = ['A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
    "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
    "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
    "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
    "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
    "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6']\n",
    "X_old = data3[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "potential-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_old\n",
    "X = StandardScaler().fit_transform(X_old)\n",
    "X = MinMaxScaler().fit_transform(X_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "august-happiness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 343, 1: 233, 2: 223, 3: 133, 4: 76, 5: 7})\n"
     ]
    }
   ],
   "source": [
    "# Summarise the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "objective-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 343, 4: 343, 3: 343, 1: 343, 2: 343, 0: 343})\n"
     ]
    }
   ],
   "source": [
    "# Oversample using SMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "secret-alloy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2058,)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "broken-present",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2058, 45)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "contrary-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOLDOUT METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "enclosed-confirmation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.404\n",
      "Linear Discriminant Analysis: 0.421\n",
      "K-Nearest Neigbors: 0.568\n",
      "Classification and Regression Trees: 0.523\n",
      "Gaussian Naive Bayes: 0.449\n",
      "Support Vector Machines: 0.413\n",
      "Random Forest Classifier: 0.728\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1)\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression:\", log_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train, y_train)\n",
    "print(\"Linear Discriminant Analysis:\", lda_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"K-Nearest Neigbors:\", knn_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X_train, y_train)\n",
    "print(\"Classification and Regression Trees:\", cart_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)\n",
    "print(\"Gaussian Naive Bayes:\", gnb_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X_train, y_train)\n",
    "print(\"Support Vector Machines:\", svm_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X_train, y_train)\n",
    "print(\"Random Forest Classifier:\", rfc_model.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "smoking-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "proper-missouri",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.43 accuracy with a standard deviation of 0.01\n",
      "Linear Discriminant Analysis: 0.45 accuracy with a standard deviation of 0.03\n",
      "K-Nearest Neighbors: 0.63 accuracy with a standard deviation of 0.07\n",
      "Classification and Regression Trees: 0.57 accuracy with a standard deviation of 0.07\n",
      "Gaussian Naive Bayes: 0.44 accuracy with a standard deviation of 0.04\n",
      "Support Vector Machines: 0.44 accuracy with a standard deviation of 0.01\n",
      "Random Forest Classifier: 0.76 accuracy with a standard deviation of 0.08\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X, y)\n",
    "scores = cross_val_score(log_model, X, y, cv=5)\n",
    "print(\"Logistic Regression: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X, y)\n",
    "scores = cross_val_score(lda_model, X, y, cv=5)\n",
    "print(\"Linear Discriminant Analysis: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5)\n",
    "print(\"K-Nearest Neighbors: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Classification and Regression Trees\n",
    "\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5)\n",
    "print(\"Classification and Regression Trees: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5)\n",
    "print(\"Gaussian Naive Bayes: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5)\n",
    "print(\"Support Vector Machines: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5)\n",
    "print(\"Random Forest Classifier: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "organized-anatomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.38      0.39        69\n",
      "           1       0.38      0.22      0.28        69\n",
      "           2       0.30      0.28      0.29        68\n",
      "           3       0.35      0.35      0.35        68\n",
      "           4       0.32      0.32      0.32        69\n",
      "           5       0.65      1.00      0.79        69\n",
      "\n",
      "    accuracy                           0.42       412\n",
      "   macro avg       0.40      0.42      0.40       412\n",
      "weighted avg       0.40      0.42      0.40       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.39      0.39        69\n",
      "           1       0.24      0.17      0.20        69\n",
      "           2       0.29      0.16      0.21        68\n",
      "           3       0.29      0.35      0.31        69\n",
      "           4       0.38      0.37      0.38        68\n",
      "           5       0.65      1.00      0.79        69\n",
      "\n",
      "    accuracy                           0.41       412\n",
      "   macro avg       0.37      0.41      0.38       412\n",
      "weighted avg       0.37      0.41      0.38       412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.32      0.31        69\n",
      "           1       0.29      0.22      0.25        68\n",
      "           2       0.31      0.23      0.27        69\n",
      "           3       0.42      0.42      0.42        69\n",
      "           4       0.47      0.43      0.45        68\n",
      "           5       0.64      1.00      0.78        69\n",
      "\n",
      "    accuracy                           0.44       412\n",
      "   macro avg       0.41      0.44      0.41       412\n",
      "weighted avg       0.41      0.44      0.41       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.38      0.34        68\n",
      "           1       0.39      0.28      0.32        68\n",
      "           2       0.45      0.30      0.36        69\n",
      "           3       0.32      0.32      0.32        69\n",
      "           4       0.47      0.39      0.43        69\n",
      "           5       0.65      1.00      0.79        68\n",
      "\n",
      "    accuracy                           0.45       411\n",
      "   macro avg       0.43      0.45      0.43       411\n",
      "weighted avg       0.43      0.45      0.43       411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.28      0.31        68\n",
      "           1       0.33      0.22      0.26        69\n",
      "           2       0.37      0.33      0.35        69\n",
      "           3       0.40      0.41      0.41        68\n",
      "           4       0.35      0.36      0.35        69\n",
      "           5       0.64      1.00      0.78        68\n",
      "\n",
      "    accuracy                           0.43       411\n",
      "   macro avg       0.41      0.43      0.41       411\n",
      "weighted avg       0.40      0.43      0.41       411\n",
      "\n",
      "[0.42475728 0.40776699 0.4368932  0.44525547 0.43309002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "scores = cross_val_score(log_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "racial-cable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.41      0.39        69\n",
      "           1       0.29      0.22      0.25        69\n",
      "           2       0.29      0.26      0.27        68\n",
      "           3       0.34      0.25      0.29        68\n",
      "           4       0.35      0.36      0.36        69\n",
      "           5       0.64      0.96      0.77        69\n",
      "\n",
      "    accuracy                           0.41       412\n",
      "   macro avg       0.38      0.41      0.39       412\n",
      "weighted avg       0.38      0.41      0.39       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.36      0.36        69\n",
      "           1       0.22      0.19      0.20        69\n",
      "           2       0.24      0.16      0.19        68\n",
      "           3       0.34      0.36      0.35        69\n",
      "           4       0.45      0.43      0.44        68\n",
      "           5       0.68      1.00      0.81        69\n",
      "\n",
      "    accuracy                           0.42       412\n",
      "   macro avg       0.38      0.42      0.39       412\n",
      "weighted avg       0.38      0.42      0.39       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.36      0.35        69\n",
      "           1       0.34      0.25      0.29        68\n",
      "           2       0.31      0.25      0.27        69\n",
      "           3       0.51      0.51      0.51        69\n",
      "           4       0.48      0.47      0.47        68\n",
      "           5       0.66      0.94      0.78        69\n",
      "\n",
      "    accuracy                           0.46       412\n",
      "   macro avg       0.44      0.46      0.45       412\n",
      "weighted avg       0.44      0.46      0.45       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.35      0.33        68\n",
      "           1       0.40      0.32      0.36        68\n",
      "           2       0.42      0.36      0.39        69\n",
      "           3       0.39      0.39      0.39        69\n",
      "           4       0.54      0.46      0.50        69\n",
      "           5       0.71      0.93      0.80        68\n",
      "\n",
      "    accuracy                           0.47       411\n",
      "   macro avg       0.46      0.47      0.46       411\n",
      "weighted avg       0.46      0.47      0.46       411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.25      0.28        68\n",
      "           1       0.33      0.25      0.28        69\n",
      "           2       0.39      0.39      0.39        69\n",
      "           3       0.53      0.56      0.54        68\n",
      "           4       0.44      0.46      0.45        69\n",
      "           5       0.74      1.00      0.85        68\n",
      "\n",
      "    accuracy                           0.48       411\n",
      "   macro avg       0.46      0.49      0.47       411\n",
      "weighted avg       0.46      0.48      0.47       411\n",
      "\n",
      "[0.41019417 0.41747573 0.46359223 0.46958637 0.48418491]\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "scores = cross_val_score(lda_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "light-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.16      0.21        69\n",
      "           1       0.33      0.20      0.25        69\n",
      "           2       0.39      0.35      0.37        68\n",
      "           3       0.41      0.56      0.47        68\n",
      "           4       0.61      0.87      0.72        69\n",
      "           5       0.86      1.00      0.93        69\n",
      "\n",
      "    accuracy                           0.52       412\n",
      "   macro avg       0.48      0.52      0.49       412\n",
      "weighted avg       0.48      0.52      0.49       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.20      0.26        69\n",
      "           1       0.36      0.32      0.34        69\n",
      "           2       0.41      0.35      0.38        68\n",
      "           3       0.55      0.67      0.61        69\n",
      "           4       0.77      0.96      0.86        68\n",
      "           5       0.78      1.00      0.88        69\n",
      "\n",
      "    accuracy                           0.58       412\n",
      "   macro avg       0.54      0.58      0.55       412\n",
      "weighted avg       0.54      0.58      0.55       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.16      0.22        69\n",
      "           1       0.62      0.46      0.53        68\n",
      "           2       0.52      0.43      0.47        69\n",
      "           3       0.61      0.86      0.72        69\n",
      "           4       0.73      0.97      0.84        68\n",
      "           5       0.80      1.00      0.89        69\n",
      "\n",
      "    accuracy                           0.65       412\n",
      "   macro avg       0.61      0.65      0.61       412\n",
      "weighted avg       0.60      0.65      0.61       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.16      0.22        68\n",
      "           1       0.62      0.49      0.55        68\n",
      "           2       0.71      0.57      0.63        69\n",
      "           3       0.60      0.86      0.70        69\n",
      "           4       0.76      0.99      0.86        69\n",
      "           5       0.82      1.00      0.90        68\n",
      "\n",
      "    accuracy                           0.68       411\n",
      "   macro avg       0.64      0.68      0.64       411\n",
      "weighted avg       0.64      0.68      0.64       411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.18      0.27        68\n",
      "           1       0.71      0.64      0.67        69\n",
      "           2       0.76      0.72      0.74        69\n",
      "           3       0.67      0.91      0.77        68\n",
      "           4       0.83      0.97      0.89        69\n",
      "           5       0.77      1.00      0.87        68\n",
      "\n",
      "    accuracy                           0.74       411\n",
      "   macro avg       0.72      0.74      0.70       411\n",
      "weighted avg       0.72      0.74      0.70       411\n",
      "\n",
      "[0.52427184 0.58252427 0.64563107 0.67639903 0.73722628]\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neigbors\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "embedded-substitute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.20      0.20        69\n",
      "           1       0.37      0.33      0.35        69\n",
      "           2       0.32      0.34      0.33        68\n",
      "           3       0.45      0.41      0.43        68\n",
      "           4       0.58      0.65      0.61        69\n",
      "           5       0.97      1.00      0.99        69\n",
      "\n",
      "    accuracy                           0.49       412\n",
      "   macro avg       0.48      0.49      0.49       412\n",
      "weighted avg       0.48      0.49      0.49       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.27        69\n",
      "           1       0.38      0.36      0.37        69\n",
      "           2       0.35      0.34      0.34        68\n",
      "           3       0.48      0.48      0.48        69\n",
      "           4       0.53      0.65      0.58        68\n",
      "           5       0.94      0.99      0.96        69\n",
      "\n",
      "    accuracy                           0.51       412\n",
      "   macro avg       0.50      0.51      0.50       412\n",
      "weighted avg       0.50      0.51      0.50       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.28      0.27        69\n",
      "           1       0.41      0.43      0.42        68\n",
      "           2       0.35      0.23      0.28        69\n",
      "           3       0.58      0.64      0.61        69\n",
      "           4       0.69      0.79      0.74        68\n",
      "           5       0.97      0.99      0.98        69\n",
      "\n",
      "    accuracy                           0.56       412\n",
      "   macro avg       0.54      0.56      0.55       412\n",
      "weighted avg       0.54      0.56      0.55       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.40      0.43        68\n",
      "           1       0.48      0.44      0.46        68\n",
      "           2       0.53      0.49      0.51        69\n",
      "           3       0.56      0.64      0.59        69\n",
      "           4       0.72      0.83      0.77        69\n",
      "           5       0.99      0.99      0.99        68\n",
      "\n",
      "    accuracy                           0.63       411\n",
      "   macro avg       0.62      0.63      0.62       411\n",
      "weighted avg       0.62      0.63      0.62       411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.32      0.35        68\n",
      "           1       0.58      0.58      0.58        69\n",
      "           2       0.62      0.64      0.63        69\n",
      "           3       0.64      0.68      0.66        68\n",
      "           4       0.71      0.74      0.72        69\n",
      "           5       0.97      1.00      0.99        68\n",
      "\n",
      "    accuracy                           0.66       411\n",
      "   macro avg       0.65      0.66      0.65       411\n",
      "weighted avg       0.65      0.66      0.65       411\n",
      "\n",
      "[0.49029126 0.50970874 0.55825243 0.63017032 0.6593674 ]\n"
     ]
    }
   ],
   "source": [
    "# Classification and Regression Trees\n",
    "cart_model = DecisionTreeClassifier()\n",
    "cart_model.fit(X, y)\n",
    "scores = cross_val_score(cart_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "fossil-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.26      0.29        69\n",
      "           1       0.23      0.20      0.22        69\n",
      "           2       0.20      0.16      0.18        68\n",
      "           3       0.26      0.47      0.33        68\n",
      "           4       0.47      0.30      0.37        69\n",
      "           5       0.96      1.00      0.98        69\n",
      "\n",
      "    accuracy                           0.40       412\n",
      "   macro avg       0.41      0.40      0.39       412\n",
      "weighted avg       0.41      0.40      0.40       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.28      0.28        69\n",
      "           1       0.36      0.20      0.26        69\n",
      "           2       0.40      0.12      0.18        68\n",
      "           3       0.21      0.36      0.27        69\n",
      "           4       0.38      0.51      0.44        68\n",
      "           5       0.90      1.00      0.95        69\n",
      "\n",
      "    accuracy                           0.41       412\n",
      "   macro avg       0.42      0.41      0.40       412\n",
      "weighted avg       0.42      0.41      0.40       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.35      0.32        69\n",
      "           1       0.22      0.16      0.19        68\n",
      "           2       0.36      0.07      0.12        69\n",
      "           3       0.33      0.65      0.43        69\n",
      "           4       0.47      0.38      0.42        68\n",
      "           5       0.90      1.00      0.95        69\n",
      "\n",
      "    accuracy                           0.44       412\n",
      "   macro avg       0.43      0.44      0.41       412\n",
      "weighted avg       0.43      0.44      0.41       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.43      0.44        68\n",
      "           1       0.45      0.19      0.27        68\n",
      "           2       0.64      0.13      0.22        69\n",
      "           3       0.34      0.77      0.47        69\n",
      "           4       0.52      0.55      0.54        69\n",
      "           5       0.92      1.00      0.96        68\n",
      "\n",
      "    accuracy                           0.51       411\n",
      "   macro avg       0.55      0.51      0.48       411\n",
      "weighted avg       0.55      0.51      0.48       411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.29      0.34        68\n",
      "           1       0.46      0.09      0.15        69\n",
      "           2       0.32      0.09      0.14        69\n",
      "           3       0.31      0.82      0.45        68\n",
      "           4       0.49      0.48      0.48        69\n",
      "           5       0.88      1.00      0.94        68\n",
      "\n",
      "    accuracy                           0.46       411\n",
      "   macro avg       0.47      0.46      0.41       411\n",
      "weighted avg       0.47      0.46      0.41       411\n",
      "\n",
      "[0.40048544 0.41262136 0.4368932  0.51094891 0.45985401]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X, y)\n",
    "scores = cross_val_score(gnb_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "valued-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.49      0.48        69\n",
      "           1       0.32      0.23      0.27        69\n",
      "           2       0.23      0.19      0.21        68\n",
      "           3       0.38      0.38      0.38        68\n",
      "           4       0.29      0.30      0.30        69\n",
      "           5       0.75      1.00      0.86        69\n",
      "\n",
      "    accuracy                           0.43       412\n",
      "   macro avg       0.41      0.43      0.42       412\n",
      "weighted avg       0.41      0.43      0.42       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.41      0.39        69\n",
      "           1       0.26      0.22      0.24        69\n",
      "           2       0.39      0.22      0.28        68\n",
      "           3       0.28      0.35      0.31        69\n",
      "           4       0.43      0.38      0.41        68\n",
      "           5       0.72      1.00      0.84        69\n",
      "\n",
      "    accuracy                           0.43       412\n",
      "   macro avg       0.41      0.43      0.41       412\n",
      "weighted avg       0.41      0.43      0.41       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.33      0.32        69\n",
      "           1       0.34      0.26      0.30        68\n",
      "           2       0.33      0.25      0.28        69\n",
      "           3       0.40      0.45      0.42        69\n",
      "           4       0.48      0.43      0.45        68\n",
      "           5       0.75      1.00      0.86        69\n",
      "\n",
      "    accuracy                           0.45       412\n",
      "   macro avg       0.43      0.45      0.44       412\n",
      "weighted avg       0.43      0.45      0.44       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.43      0.36        68\n",
      "           1       0.37      0.32      0.35        68\n",
      "           2       0.44      0.26      0.33        69\n",
      "           3       0.29      0.32      0.31        69\n",
      "           4       0.43      0.33      0.37        69\n",
      "           5       0.76      1.00      0.87        68\n",
      "\n",
      "    accuracy                           0.44       411\n",
      "   macro avg       0.43      0.44      0.43       411\n",
      "weighted avg       0.43      0.44      0.43       411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.26      0.28        68\n",
      "           1       0.30      0.17      0.22        69\n",
      "           2       0.34      0.29      0.31        69\n",
      "           3       0.35      0.44      0.39        68\n",
      "           4       0.36      0.41      0.38        69\n",
      "           5       0.76      1.00      0.86        68\n",
      "\n",
      "    accuracy                           0.43       411\n",
      "   macro avg       0.40      0.43      0.41       411\n",
      "weighted avg       0.40      0.43      0.41       411\n",
      "\n",
      "[0.43446602 0.42961165 0.4538835  0.44282238 0.42822384]\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svm_model = SVC(kernel='linear', gamma = 'auto')\n",
    "svm_model.fit(X, y)\n",
    "scores = cross_val_score(svm_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "ambient-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.57      0.48        69\n",
      "           1       0.63      0.46      0.53        69\n",
      "           2       0.44      0.46      0.45        68\n",
      "           3       0.77      0.59      0.67        68\n",
      "           4       0.81      0.91      0.86        69\n",
      "           5       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           0.67       412\n",
      "   macro avg       0.68      0.66      0.67       412\n",
      "weighted avg       0.68      0.67      0.67       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.55      0.49        69\n",
      "           1       0.49      0.54      0.51        69\n",
      "           2       0.70      0.49      0.57        68\n",
      "           3       0.71      0.65      0.68        69\n",
      "           4       0.94      0.97      0.96        68\n",
      "           5       0.97      1.00      0.99        69\n",
      "\n",
      "    accuracy                           0.70       412\n",
      "   macro avg       0.71      0.70      0.70       412\n",
      "weighted avg       0.71      0.70      0.70       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.45      0.45        69\n",
      "           1       0.63      0.60      0.62        68\n",
      "           2       0.65      0.45      0.53        69\n",
      "           3       0.76      0.94      0.84        69\n",
      "           4       0.87      0.97      0.92        68\n",
      "           5       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           0.74       412\n",
      "   macro avg       0.73      0.74      0.73       412\n",
      "weighted avg       0.73      0.74      0.73       412\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59        68\n",
      "           1       0.73      0.69      0.71        68\n",
      "           2       0.76      0.74      0.75        69\n",
      "           3       0.87      0.97      0.92        69\n",
      "           4       0.91      0.99      0.94        69\n",
      "           5       1.00      1.00      1.00        68\n",
      "\n",
      "    accuracy                           0.82       411\n",
      "   macro avg       0.82      0.82      0.82       411\n",
      "weighted avg       0.82      0.82      0.82       411\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.35      0.48        68\n",
      "           1       0.81      0.90      0.85        69\n",
      "           2       0.72      0.93      0.81        69\n",
      "           3       0.83      0.96      0.89        68\n",
      "           4       0.99      0.97      0.98        69\n",
      "           5       1.00      1.00      1.00        68\n",
      "\n",
      "    accuracy                           0.85       411\n",
      "   macro avg       0.85      0.85      0.84       411\n",
      "weighted avg       0.85      0.85      0.84       411\n",
      "\n",
      "[0.66504854 0.69902913 0.73543689 0.82481752 0.85158151]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "fluid-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Performance Metrics for Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "driven-promise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for Logistic Regression:\n",
      "\n",
      "0.40413 \n",
      "\n",
      "[[ 46   8  29  29  15  11]\n",
      " [ 18  24  21  26  34  18]\n",
      " [ 35  15  32  24  17  11]\n",
      " [ 35  21  13  44  16  10]\n",
      " [ 21  19  19   7  51  19]\n",
      " [  0   0   0   0   0 136]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.33      0.31       138\n",
      "           1       0.28      0.17      0.21       141\n",
      "           2       0.28      0.24      0.26       134\n",
      "           3       0.34      0.32      0.33       139\n",
      "           4       0.38      0.38      0.38       136\n",
      "           5       0.66      1.00      0.80       136\n",
      "\n",
      "    accuracy                           0.40       824\n",
      "   macro avg       0.37      0.41      0.38       824\n",
      "weighted avg       0.37      0.40      0.38       824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahi\\anaconda3\\envs\\FYP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Logistic Regression\n",
    "log_model.fit(X_train, y_train)\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for Logistic Regression:\\n')\n",
    "print(accuracy_score(y_test, log_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, log_pred), '\\n')\n",
    "print(classification_report(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "attended-color",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for LDA:\n",
      "\n",
      "0.42112 \n",
      "\n",
      "[[ 48  11  33  25  15   6]\n",
      " [ 20  33  25  22  26  15]\n",
      " [ 32  17  40  19  19   7]\n",
      " [ 35  27  19  44   9   5]\n",
      " [  9  27  27   8  51  14]\n",
      " [  0   0   5   0   0 131]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.35      0.34       138\n",
      "           1       0.29      0.23      0.26       141\n",
      "           2       0.27      0.30      0.28       134\n",
      "           3       0.37      0.32      0.34       139\n",
      "           4       0.42      0.38      0.40       136\n",
      "           5       0.74      0.96      0.83       136\n",
      "\n",
      "    accuracy                           0.42       824\n",
      "   macro avg       0.40      0.42      0.41       824\n",
      "weighted avg       0.40      0.42      0.41       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for LDA\n",
    "lda_model.fit(X_train, y_train)\n",
    "lda_pred = lda_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for LDA:\\n')\n",
    "print(accuracy_score(y_test, lda_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, lda_pred), '\\n')\n",
    "print(classification_report(y_test, lda_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "statistical-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for KNN:\n",
      "\n",
      "0.56796 \n",
      "\n",
      "[[ 28  25  29  27  21   8]\n",
      " [ 18  42  15  29  22  15]\n",
      " [ 16  20  57  19  13   9]\n",
      " [ 19  16   8  86   9   1]\n",
      " [  1   4   5   7 119   0]\n",
      " [  0   0   0   0   0 136]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.20      0.25       138\n",
      "           1       0.39      0.30      0.34       141\n",
      "           2       0.50      0.43      0.46       134\n",
      "           3       0.51      0.62      0.56       139\n",
      "           4       0.65      0.88      0.74       136\n",
      "           5       0.80      1.00      0.89       136\n",
      "\n",
      "    accuracy                           0.57       824\n",
      "   macro avg       0.53      0.57      0.54       824\n",
      "weighted avg       0.53      0.57      0.54       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for kNN\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for KNN:\\n')\n",
    "print(accuracy_score(y_test, knn_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, knn_pred), '\\n')\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "neither-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for CART:\n",
      "\n",
      "0.52549 \n",
      "\n",
      "[[ 45  24  29  26  13   1]\n",
      " [ 20  54  21  21  22   3]\n",
      " [ 25  29  43  16  21   0]\n",
      " [ 18  16  18  79   7   1]\n",
      " [ 14  25  14   4  77   2]\n",
      " [  0   0   0   1   0 135]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.33      0.35       138\n",
      "           1       0.36      0.38      0.37       141\n",
      "           2       0.34      0.32      0.33       134\n",
      "           3       0.54      0.57      0.55       139\n",
      "           4       0.55      0.57      0.56       136\n",
      "           5       0.95      0.99      0.97       136\n",
      "\n",
      "    accuracy                           0.53       824\n",
      "   macro avg       0.52      0.53      0.52       824\n",
      "weighted avg       0.52      0.53      0.52       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for CART\n",
    "cart_model.fit(X_train, y_train)\n",
    "cart_pred = cart_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for CART:\\n')\n",
    "print(accuracy_score(y_test, cart_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, cart_pred), '\\n')\n",
    "print(classification_report(y_test, cart_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "split-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for GNB:\n",
      "\n",
      "0.40413 \n",
      "\n",
      "[[ 46   8  29  29  15  11]\n",
      " [ 18  24  21  26  34  18]\n",
      " [ 35  15  32  24  17  11]\n",
      " [ 35  21  13  44  16  10]\n",
      " [ 21  19  19   7  51  19]\n",
      " [  0   0   0   0   0 136]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.33      0.31       138\n",
      "           1       0.28      0.17      0.21       141\n",
      "           2       0.28      0.24      0.26       134\n",
      "           3       0.34      0.32      0.33       139\n",
      "           4       0.38      0.38      0.38       136\n",
      "           5       0.66      1.00      0.80       136\n",
      "\n",
      "    accuracy                           0.40       824\n",
      "   macro avg       0.37      0.41      0.38       824\n",
      "weighted avg       0.37      0.40      0.38       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for GNB\n",
    "gnb_model.fit(X_train, y_train)\n",
    "gnb_pred = log_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for GNB:\\n')\n",
    "print(accuracy_score(y_test, gnb_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, gnb_pred), '\\n')\n",
    "print(classification_report(y_test, gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "hungry-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for SVM:\n",
      "\n",
      "0.41262 \n",
      "\n",
      "[[ 52  10  28  25  15   8]\n",
      " [ 19  21  23  25  39  14]\n",
      " [ 37  13  37  21  16  10]\n",
      " [ 37  25  12  43  16   6]\n",
      " [ 26  25  13   8  51  13]\n",
      " [  0   0   0   0   0 136]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.38      0.34       138\n",
      "           1       0.22      0.15      0.18       141\n",
      "           2       0.33      0.28      0.30       134\n",
      "           3       0.35      0.31      0.33       139\n",
      "           4       0.37      0.38      0.37       136\n",
      "           5       0.73      1.00      0.84       136\n",
      "\n",
      "    accuracy                           0.41       824\n",
      "   macro avg       0.38      0.41      0.39       824\n",
      "weighted avg       0.38      0.41      0.39       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Support Vector Machine\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for SVM:\\n')\n",
    "print(accuracy_score(y_test, svm_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, svm_pred), '\\n')\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "unlike-spank",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for RFC:\n",
      "\n",
      "0.70024 \n",
      "\n",
      "[[ 69  21  30  16   2   0]\n",
      " [ 29  67  20  14  11   0]\n",
      " [ 30  12  75  13   3   1]\n",
      " [ 14   4   7 112   1   1]\n",
      " [  9   5   3   1 118   0]\n",
      " [  0   0   0   0   0 136]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48       138\n",
      "           1       0.61      0.48      0.54       141\n",
      "           2       0.56      0.56      0.56       134\n",
      "           3       0.72      0.81      0.76       139\n",
      "           4       0.87      0.87      0.87       136\n",
      "           5       0.99      1.00      0.99       136\n",
      "\n",
      "    accuracy                           0.70       824\n",
      "   macro avg       0.70      0.70      0.70       824\n",
      "weighted avg       0.70      0.70      0.70       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for Random Forest Classifier\n",
    "rfc_model.fit(X_train, y_train)\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for RFC:\\n')\n",
    "print(accuracy_score(y_test, rfc_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, rfc_pred), '\\n')\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
