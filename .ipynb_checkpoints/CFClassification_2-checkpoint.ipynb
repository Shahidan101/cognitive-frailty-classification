{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4b257554db26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import decomposition\n",
    "from collections import Counter\n",
    "from parse import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show classification report for Cross Validation\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-parse the dataset\n",
    "data = preprocess(\"rawfile_blood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = data['condition'].value_counts()\n",
    "condition = c.index\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(data)):\n",
    "# \tif data.at[i, 'condition'] == 'frail':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'frail_mci':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'mci':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'prefrail_mci':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'prefrail':\n",
    "# \t\tdata.at[i, 'condition'] = 'non-robust'\n",
    "# \telif data.at[i, 'condition'] == 'robust':\n",
    "# \t\tdata.at[i, 'condition'] = 'robust'\n",
    "\n",
    "# df1 = data[data.condition != 'frail']\n",
    "# df1 = df1.reset_index(drop=True)\n",
    "\n",
    "# df2 = data[data.condition == 'robust']\n",
    "# df2 = df2.reset_index(drop=True)\n",
    "\n",
    "df = data\n",
    "\n",
    "c = df['condition'].value_counts()\n",
    "condition = c.index\n",
    "c\n",
    "\n",
    "# data = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(condition)):\n",
    "    df['condition'].replace(condition[i], i, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['condition']\n",
    "\n",
    "features = ['A1_1', 'A2_1', 'A3_1', 'B1_a', 'B1_a1', 'B1_a2',\n",
    "       'B1_a3', 'B1_a4', 'B1_a5', 'B1_a6', 'B1_b', 'B1_b1', 'B1_b2', 'B1_b3',\n",
    "       'B1_c', 'B1_d', 'B2_a1', 'B2_a2', 'B2_a3', 'B2_a4', 'B2_a5', 'B2_b1',\n",
    "       'B2_b2', 'B2_b3', 'B2_c1', 'B2_c2', 'B2_c4', 'B2_c5', 'B2_c6', 'B2_c7',\n",
    "       'B2_d1', 'B2_d2', 'B2_d3', 'B2_d4', 'B2_d5', 'B2_d6', 'B2_d7', 'B2_d8',\n",
    "       'B2_d9', 'B3', 'B4_a2', 'B4_a5', 'B5_a2', 'B5_a3', 'B6']\n",
    "\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "\n",
    "# Create Random Forest Classifier Model\n",
    "rfc_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Build the model\n",
    "rfc_model.fit(X, y)\n",
    "\n",
    "features = X.columns\n",
    "importances = rfc_model.feature_importances_\n",
    "indices = np.argsort(importances)[-9:]  # top 10 features\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Conduct mapping for Feature Names\n",
    "featureName_mapping = {\n",
    "    \"A1_1\" : \"Vitamin B12 (pmol/L)\",\n",
    "    \"A1_2\" : \"Serum Folate (nmol/L)\",\n",
    "    \"A2_1\" : \"Serum Homocysteine (µmol/L)\",\n",
    "    \"A3_1\" : \"25-hydroxy Vitamin D (nmol/L)\",\n",
    "    \"B1_a\" : \"Haemoglobin (g/L)\",\n",
    "    \"B1_a1\" : \"RBC (/L)\",\n",
    "    \"B1_a2\" : \"PCV (L/L)\",\n",
    "    \"B1_a3\" : \"MCV (fL)\",\n",
    "    \"B1_a4\" : \"MCH (pg)\",\n",
    "    \"B1_a5\" : \"MCHC (g/L)\",\n",
    "    \"B1_a6\" : \"RDW (%)\",\n",
    "    \"B1_b\" : \"White Cell Count (/L)\",\n",
    "    \"B1_b1\" : \"Neutrophils (/L)\",\n",
    "    \"B1_b2\" : \"Lymphocytes (/L)\",\n",
    "    \"B1_b3\" : \"Monocytes (/L)\",\n",
    "    \"B1_b4\" : \"Eosinophils (/L)\",\n",
    "    \"B1_b5\" : \"Basophils (/L)\",\n",
    "    \"B1_c\" : \"Platelets (/L)\",\n",
    "    \"B1_d\" : \"Glucose (mmol/L)\",\n",
    "    \"B2_a1\" : \"Total Cholesterol (mmol/L)\",\n",
    "    \"B2_a2\" : \"Triglyceride (mmol/L)\",\n",
    "    \"B2_a3\" : \"HDL Cholesterol (mmol/L)\",\n",
    "    \"B2_a4\" : \"LDL Cholesterol (mmol/L)\",\n",
    "    \"B2_a5\" : \"Total Cholesterol/HDL Ratio\",\n",
    "    \"B2_b1\" : \"Sodium (mmol/L)\",\n",
    "    \"B2_b2\" : \"Potassium (mmol/L)\",\n",
    "    \"B2_b3\" : \"Chloride (mmol/L)\",\n",
    "    \"B2_c1\" : 'Urea (mmol/L)',\n",
    "    \"B2_c2\" : \"Creatinine (umol/L)\",\n",
    "    \"B2_c3\" : \"eGFR (mL/min/1.73m2)\",\n",
    "    \"B2_c4\" : \"Uric Acid (mmol/L)\",\n",
    "    \"B2_c5\" : \"Calcium (mmol/L)\",\n",
    "    \"B2_c6\" : \"Corrected Calcium (mmol/L)\",\n",
    "    \"B2_c7\" : \"Phosphate (mmol/L)\",\n",
    "    \"B2_d1\" : \"Total Protein (g/L)\",\n",
    "    \"B2_d2\" : \"Albumin (g/L)\",\n",
    "    \"B2_d3\" : \"Globulin (g/L)\",\n",
    "    \"B2_d4\" : \"Albumin/Globulin ratio\",\n",
    "    \"B2_d5\" : \"Alkaline Phosphatase (U/L)\",\n",
    "    \"B2_d6\" : \"Total Bilirubin (µmol/L)\",\n",
    "    \"B2_d7\" : \"GGT\",\n",
    "    \"B2_d8\" : \"AST\",\n",
    "    \"B2_d9\" : \"ALT\",\n",
    "    \"B3\" : \"C-Reactive Protein\",\n",
    "    \"B4_a1\" : \"Protein\",\n",
    "    \"B4_a2\" : \"pH\",\n",
    "    \"B4_a3\" : \"Glucose\",\n",
    "    \"B4_a4\" : \"Ketones\",\n",
    "    \"B4_a5\" : \"S.G.\",\n",
    "    \"B4_a6\" : \"Blood\",\n",
    "    \"B4_b1\" : \"Leucocytes (/L)\",\n",
    "    \"B4_b2\" : \"Erythrocytes (/L)\",\n",
    "    \"B4_b3\" : \"Epithelial Cells\",\n",
    "    \"B5_a1\" : \"Free Thyroxine (FT4) (pmol/L)\",\n",
    "    \"B5_a2\" : \"Thyroid Stimulating Hormone (mIU/L)\",\n",
    "    \"B5_a3\" : \"Free Tri-iodothyronine (FT3) (pmol/L)\",\n",
    "    \"B6\" : \"HbA1c\"\n",
    "}\n",
    "\n",
    "df_dummy = pd.Series(features)\n",
    "df_dummy = df_dummy.map(featureName_mapping)\n",
    "\n",
    "listing = []\n",
    "\n",
    "for items in indices:\n",
    "    listing.append(items)\n",
    "    \n",
    "listing.reverse()\n",
    "newfeatures = []\n",
    "\n",
    "for i in listing:\n",
    "    print(features[i], \"-->\", df_dummy[i])\n",
    "    newfeatures.append(features[i])\n",
    "\n",
    "X = df[newfeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "# Create Random Forest Classifier Model\n",
    "rfc_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Build the model\n",
    "rfc_model.fit(X, y)\n",
    "\n",
    "features = X.columns\n",
    "importances = rfc_model.feature_importances_\n",
    "indices = np.argsort(importances)[-9:]  # top 10 features\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = StandardScaler().fit_transform(X)\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 343, 1: 233, 2: 223, 3: 133, 4: 76, 5: 7})\n"
     ]
    }
   ],
   "source": [
    "# Summarise the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the majority class\n",
    "# Define undersample strategy\n",
    "\n",
    "# 75% of majority class\n",
    "# sampling_strategy = {0: 254, 1: 231, 2: 221, 3: 133, 4: 76, 5: 7}\n",
    "\n",
    "# 50% of majority class\n",
    "# sampling_strategy = {0: 170, 1: 170, 2: 170, 3: 133, 4: 76, 5: 7}\n",
    "\n",
    "# 25% of majority class\n",
    "# sampling_strategy = {0: 85, 1: 85, 2: 85, 3: 85, 4: 76, 5: 7}\n",
    "\n",
    "# sampling_strategy = {'robust': 223, 'prefrail_mci': 223, 'prefrail': 223, 'mci': 133, 'frail_mci': 76}\n",
    "# sampling_strategy = {0: 254, 1: 233, 2: 223, 3: 133, 4: 76, 5: 7}\n",
    "# undersample = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "\n",
    "# 50% of majority class\n",
    "# undersample = RandomUnderSampler(sampling_strategy=0.0413)\n",
    "\n",
    "# 25% of majority class\n",
    "# undersample = RandomUnderSampler(sampling_strategy=0.0826)\n",
    "\n",
    "# X, y = undersample.fit_resample(X, y)\n",
    "\n",
    "# Summarise the new class distribution\n",
    "# counter = Counter(y)\n",
    "# print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 343, 4: 343, 3: 343, 1: 343, 2: 343, 0: 343})\n"
     ]
    }
   ],
   "source": [
    "# Transform the dataset using SMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "# Summarise the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neigbors: 0.539\n",
      "Random Forest Classifier: 0.652\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1)\n",
    "\n",
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "print(\"K-Nearest Neigbors:\", knn_model.score(X_test, y_test).round(3))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(random_state=1)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "print(\"Random Forest Classifier:\", rfc_model.score(X_test, y_test).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics for KNN:\n",
      "\n",
      "0.53883 \n",
      "\n",
      "[[ 41  25  22  16  22  12]\n",
      " [ 21  53  16  18  19  14]\n",
      " [ 29  19  30  25  24   7]\n",
      " [ 25  10   7  81  11   5]\n",
      " [  5   9   1  11 103   7]\n",
      " [  0   0   0   0   0 136]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.30      0.32       138\n",
      "           1       0.46      0.38      0.41       141\n",
      "           2       0.39      0.22      0.29       134\n",
      "           3       0.54      0.58      0.56       139\n",
      "           4       0.58      0.76      0.65       136\n",
      "           5       0.75      1.00      0.86       136\n",
      "\n",
      "    accuracy                           0.54       824\n",
      "   macro avg       0.51      0.54      0.51       824\n",
      "weighted avg       0.51      0.54      0.51       824\n",
      "\n",
      "Performance Metrics for RFC:\n",
      "\n",
      "0.6517 \n",
      "\n",
      "[[ 49  28  31  18   9   3]\n",
      " [ 21  73  18  12  13   4]\n",
      " [ 28  16  68  10  12   0]\n",
      " [ 16   5  10  95   7   6]\n",
      " [  5   5   4   6 116   0]\n",
      " [  0   0   0   0   0 136]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.36      0.38       138\n",
      "           1       0.57      0.52      0.54       141\n",
      "           2       0.52      0.51      0.51       134\n",
      "           3       0.67      0.68      0.68       139\n",
      "           4       0.74      0.85      0.79       136\n",
      "           5       0.91      1.00      0.95       136\n",
      "\n",
      "    accuracy                           0.65       824\n",
      "   macro avg       0.64      0.65      0.64       824\n",
      "weighted avg       0.64      0.65      0.64       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating for KNN\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for KNN:\\n')\n",
    "print(accuracy_score(y_test, knn_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, knn_pred), '\\n')\n",
    "print(classification_report(y_test, knn_pred))\n",
    "\n",
    "# Calculating for RFC\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "\n",
    "print('Performance Metrics for RFC:\\n')\n",
    "print(accuracy_score(y_test, rfc_pred).round(5), '\\n')\n",
    "print(confusion_matrix(y_test, rfc_pred), '\\n')\n",
    "print(classification_report(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors: 0.63 accuracy with a standard deviation of 0.05\n",
      "Random Forest Classifier: 0.71 accuracy with a standard deviation of 0.06\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neigbors\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X, y)\n",
    "scores = cross_val_score(knn_model, X, y, cv=5)\n",
    "print(\"K-Nearest Neighbors: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rfc_model = RandomForestClassifier()\n",
    "rfc_model.fit(X, y)\n",
    "scores = cross_val_score(rfc_model, X, y, cv=5)\n",
    "print(\"Random Forest Classifier: %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
