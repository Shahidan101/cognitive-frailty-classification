{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from parse import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess(\"rawfile_blood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise counters for each condition\n",
    "frail = 0\n",
    "frail_mci = 0\n",
    "mci = 0\n",
    "prefrail_mci = 0\n",
    "prefrail = 0\n",
    "robust = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows of data for each condition\n",
    "for i in range(0, len(df)):\n",
    "\tif df.at[i, 'condition'] == 'frail':\n",
    "\t\tfrail += 1\n",
    "\telif df.at[i, 'condition'] == 'frail_mci':\n",
    "\t\tfrail_mci += 1\n",
    "\telif df.at[i, 'condition'] == 'mci':\n",
    "\t\tmci += 1\n",
    "\telif df.at[i, 'condition'] == 'prefrail_mci':\n",
    "\t\tprefrail_mci += 1\n",
    "\telif df.at[i, 'condition'] == 'prefrail':\n",
    "\t\tprefrail += 1\n",
    "\telif df.at[i, 'condition'] == 'robust':\n",
    "\t\trobust += 1\n",
    "        \n",
    "# Display number of rows (frequency) for each condition (label)\n",
    "print(\"\\n####################################################################\")\n",
    "print(\"Labels with frequencies:\")\n",
    "print(\"Frail:\", frail)\n",
    "print(\"Frail + MCI:\", frail_mci)\n",
    "print(\"MCI:\", mci)\n",
    "print(\"Prefrail + MCI:\", prefrail_mci)\n",
    "print(\"Prefrail:\", prefrail)\n",
    "print(\"Robust:\", robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify features and labels\n",
    "y = df['condition']\n",
    "x = df.drop(['mtag', 'condition'], axis=1)\n",
    "\n",
    "# Display features and labels\n",
    "print(x, y)\n",
    "\n",
    "# Display shape of features and labels\n",
    "print(\"\\nShape of Features:\")\n",
    "print(x.shape)\n",
    "print(\"\\nShape of Labels:\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Dictionary:\n",
    "# frail -> 0\n",
    "# frail_mci -> 1\n",
    "# mci -> 2\n",
    "# prefrail_mci -> 3\n",
    "# prefrail -> 4\n",
    "# robust -> 5\n",
    "\n",
    "# Conduct label mapping for conditions\n",
    "label_mapping = {\n",
    "    'frail' : 0,\n",
    "    'frail_mci' : 1,\n",
    "    'mci' : 2,\n",
    "    'prefrail_mci' : 3,\n",
    "    'prefrail' : 4,\n",
    "    'robust' : 5\n",
    "}\n",
    "\n",
    "y = y.map(label_mapping)\n",
    "y = np.array(y)\n",
    "\n",
    "# Display label\n",
    "print(y)\n",
    "\n",
    "# Display shape of label\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct train-test split on dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Display x_train, x_test, y_train, y_test\n",
    "print(\"\\nX Train:\")\n",
    "print(x_train)\n",
    "print(\"\\nX Test:\")\n",
    "print(x_test)\n",
    "print(\"\\nY Train:\")\n",
    "print(y_train)\n",
    "print(\"\\nY Test:\")\n",
    "print(y_test)\n",
    "\n",
    "# Display shape of train and test sets\n",
    "print(\"\\nShape of X Train:\")\n",
    "print(x_train.shape)\n",
    "print(\"\\nShape of X Test:\")\n",
    "print(x_test.shape)\n",
    "print(\"\\nShape of Y Train:\")\n",
    "print(y_train.shape)\n",
    "print(\"\\nShape of Y Test:\")\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear SVM model\n",
    "model = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Measure accuracy\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print predictions, actual, and accuracy score\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Actual:\", y_test)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RBF SVM model\n",
    "model = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Measure accuracy\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print predictions, actual, and accuracy score\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Actual:\", y_test)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sigmoid SVM model\n",
    "model = svm.SVC(kernel='sigmoid')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Measure accuracy\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print predictions, actual, and accuracy score\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Actual:\", y_test)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Polynomial SVM model\n",
    "model = svm.SVC(kernel='poly')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Measure accuracy\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print predictions, actual, and accuracy score\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Actual:\", y_test)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
